<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Alyssa]]></title>
  <subtitle><![CDATA[Alyssa Quek]]></subtitle>
  <link href="/atom.xml" rel="self"/>
  <link href="alyssaq.github.io/"/>
  <updated>2015-10-18T08:46:46.000Z</updated>
  <id>alyssaq.github.io/</id>
  
  <author>
    <name><![CDATA[Alyssa Quek]]></name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title><![CDATA[Site Deployment With Gzipped Assets to AWS S3 Using CircleCI]]></title>
    <link href="alyssaq.github.io/2015/deploy_gzip_site_s3/"/>
    <id>alyssaq.github.io/2015/deploy_gzip_site_s3/</id>
    <published>2015-04-16T10:02:00.000Z</published>
    <updated>2015-10-18T08:46:46.000Z</updated>
    <content type="html"><![CDATA[<p>I’ve been using <a href="https://www.heroku.com" target="_blank" rel="external">Heroku</a> and <a href="https://cloud.google.com/appengine/docs" target="_blank" rel="external">Google App Engine</a> to host most of my web applications. This time, I decided to use <a href="http://aws.amazon.com/s3" target="_blank" rel="external">Amazon S3</a> to serve a static website.</p>
<h2 id="Amazon_S3_setup">Amazon S3 setup</h2><p>After creating your S3 bucket, click on the <code>Properties</code> button.</p>
<p>1) Enable static website hosting. For single page apps, specify the same error and index document.</p>
<p><img src="https://alyssaq.github.io/blog/images/S3deploy_enable-static-site.png" alt="s3_static_config"></p>
<p>2) Under Permissions &gt; Edit CORS Configuration, make all files in this bucket accessible to the public by pasting this XML:</p>
<pre><code><span class="pi">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span>
<span class="tag">&lt;<span class="title">CORSConfiguration</span> <span class="attribute">xmlns</span>=<span class="value">"http://s3.amazonaws.com/doc/2006-03-01/"</span>&gt;</span>
    <span class="tag">&lt;<span class="title">CORSRule</span>&gt;</span>
        <span class="tag">&lt;<span class="title">AllowedOrigin</span>&gt;</span>*<span class="tag">&lt;/<span class="title">AllowedOrigin</span>&gt;</span>
        <span class="tag">&lt;<span class="title">AllowedMethod</span>&gt;</span>GET<span class="tag">&lt;/<span class="title">AllowedMethod</span>&gt;</span>
        <span class="tag">&lt;<span class="title">MaxAgeSeconds</span>&gt;</span>3000<span class="tag">&lt;/<span class="title">MaxAgeSeconds</span>&gt;</span>
        <span class="tag">&lt;<span class="title">AllowedHeader</span>&gt;</span>Authorization<span class="tag">&lt;/<span class="title">AllowedHeader</span>&gt;</span>
        <span class="tag">&lt;<span class="title">AllowedHeader</span>&gt;</span>Content-Type<span class="tag">&lt;/<span class="title">AllowedHeader</span>&gt;</span>
    <span class="tag">&lt;/<span class="title">CORSRule</span>&gt;</span>
<span class="tag">&lt;/<span class="title">CORSConfiguration</span>&gt;</span>
</code></pre><p>There are 2 save buttons. Per section and global save, so click em all!</p>
<h2 id="Gzip_assets_with_gulp">Gzip assets with gulp</h2><p>Unfortunately, S3 does not automatically compress assets. Here is their <a href="http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/ServingCompressedFiles.html#CompressedS3" target="_blank" rel="external">verbose instructions for serving compressed files</a>.  </p>
<p>Basically,    </p>
<ol>
<li>gzip assets</li>
<li>Set header with <code>Content-Encoding: gzip</code></li>
</ol>
<p>Yes, my JS and CSS assets are always gzipped and ancient browsers (such as IE &lt; 5, Firefox &lt; 0.9.5) are not supported. Code for the future!</p>
<p>I gzip as part of my <a href="http://gulpjs.com" target="_blank" rel="external">gulp</a> build.</p>
<p>Heres the relevant gulp <code>build</code> task:</p>
<pre><code class="language-javascript">
gulp.task('build', ['clean'], function () {
  gulp.start('default', function() {
    return gulp.src('dist/**/*')
      .pipe($.size({title: 'build', gzip: true}))
      .pipe($.if('*.js', $.gzip({ append: false })))
      .pipe($.if('*.css', $.gzip({ append: false })))
      .pipe(gulp.dest('dist'))
  })
})
</code></pre>

<p>I run <code>clean</code> (to delete destination folder), then the <code>default</code> task (to browserify, babelify, concatenate, minify, replace, etc) and then <code>gzip</code> only the minified JS and CSS assets.</p>
<p><code>$.gzip({ append: false })</code> replaces the file with the gzipped version and pipes to the <code>dest</code> folder. Setting to true appends <code>.gz</code>.</p>
<p>The npm gulp packages involved in this step:</p>
<pre><code>$ npm <span class="operator"><span class="keyword">install</span> gulp-<span class="keyword">load</span>-plugins gulp-<span class="keyword">if</span> gulp-gzip </span>
</code></pre><h2 id="Auto-deploy_with_CircleCI">Auto-deploy with CircleCI</h2><p>In the CircleCI project settings &gt; AWS Permissions, set your Amazon <code>Access Key ID</code> and <code>Secret Access Key</code> from an IAM user with S3 PutObject and GetObject permissions (<a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/using-with-s3-actions.html" target="_blank" rel="external">Amazon S3 permission list</a>). I started off with a user that had permissions to all S3 actions and then pruned later.</p>
<p>To deploy the app to S3, circleCI runs <code>gulp build</code> and sync the <code>dist</code> folder with <a href="http://docs.aws.amazon.com/cli/latest/reference/s3/sync.html" target="_blank" rel="external">AWS CLI sync</a>.</p>
<p>My <code>circle.yml</code>:</p>
<pre class="language-yml"><code class="language-yml">
machine:
  node:
    version: 0.12.0
dependencies:
  post:
    - npm install -g gulp-cli && gulp build
deployment:
  production:
    branch: master
    commands:
      - sudo pip install awscli
      - aws s3 sync dist/ s3://newcleus-app --exclude "*" --include "*.css" --include "*.js"
 --content-encoding gzip --cache-control public,max-age=30672000
      - aws s3 sync dist/ s3://newcleus-app --exclude "*.js" --exclude "*.css"
</code></pre>

<p>Under <code>deployment</code>, the first <code>aws s3</code> command adds the <code>Content-Encoding: gzip</code> and <code>Cache-Control</code> headers to the JS and CSS assets. The second command syncs the remaining files.</p>
<h2 id="Overall">Overall</h2><p>On my Mac, I use <a href="https://cyberduck.io" target="_blank" rel="external">Cyberduck</a> to view all files in all my S3 buckets.</p>
<p>In the end, while not as friendly as Heroku, I was pretty happy with this auto-deployment to S3.</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>I’ve been using <a href="https://www.heroku.com" target="_blank" rel="external">Heroku</a> and <a href="https://cloud.google.com/appengin]]>
    </summary>
    
      <category term="automation" scheme="alyssaq.github.io/tags/automation/"/>
    
      <category term="aws" scheme="alyssaq.github.io/tags/aws/"/>
    
      <category term="tech" scheme="alyssaq.github.io/categories/tech/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Face Morpher Talk at FOSS Asia]]></title>
    <link href="alyssaq.github.io/2015/face-morpher-talk-at-foss-asia/"/>
    <id>alyssaq.github.io/2015/face-morpher-talk-at-foss-asia/</id>
    <published>2015-03-14T11:08:00.000Z</published>
    <updated>2015-10-18T08:46:36.000Z</updated>
    <content type="html"><![CDATA[<p>I just presented at FOSS Asia (free open source software) conference.<br>I talked about face morphing and averaging using Python.</p>
<p>Slides: <a href="http://alyssaq.github.io/face_morpher_slides">http://alyssaq.github.io/face_morpher_slides</a><br>Code: <a href="http://github.com/alyssaq/face_morpher" target="_blank" rel="external">http://github.com/alyssaq/face_morpher</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>I just presented at FOSS Asia (free open source software) conference.<br>I talked about face morphing and averaging using Python.</p>
<p>]]>
    </summary>
    
      <category term="python" scheme="alyssaq.github.io/tags/python/"/>
    
      <category term="stuff" scheme="alyssaq.github.io/categories/stuff/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Singular Value Decomposition (SVD) Visualisation]]></title>
    <link href="alyssaq.github.io/2015/singular-value-decomposition-visualisation/"/>
    <id>alyssaq.github.io/2015/singular-value-decomposition-visualisation/</id>
    <published>2015-02-23T19:03:00.000Z</published>
    <updated>2015-10-18T08:46:32.000Z</updated>
    <content type="html"><![CDATA[<p><a href="https://books.google.com.sg/books?id=MjNwWUY8jx4C&amp;pg=PA259" target="_blank" rel="external">“The SVD is absolutely a high point of linear algebra” (Gilbert Strang, Kai Borre)</a></p>
<p>This mathematical technique has been used across various industries and example applications include <a href="http://www2.research.att.com/~volinsky/papers/ieeecomputer.pdf" target="_blank" rel="external">recommender systems (Netflix prize)</a>, <a href="http://www.iaarc.org/publications/fulltext/isarc2007-4.5_4_035.pdf" target="_blank" rel="external">face and object recognition</a>, <a href="http://www.orie.cornell.edu/engineering2/customcf/iws_events_calendar/files/Marco_Avellaneda_Presentation_10_16_14.pdf" target="_blank" rel="external">risk modelling in equity options</a> and <a href="http://www.ncbi.nlm.nih.gov/pubmed/12045141" target="_blank" rel="external">identifying genes in brain imaging that make up Parkinson disease</a>. </p>
<h2 id="Definition">Definition</h2><p>SVD is a matrix factorisation and decomposes a matrix of any size into a  product of 3 matrices:</p>
<p>$$ A = U S V^T $$</p>
<p>$A$ : $n \times m$ : number of records as rows and number of dimensions/features as columns.<br>$U$ : $n \times n$ : orthogonal matrix containing eigenvectors of $AA^T$.<br>$S$ : $n \times m$ : ordered singular values in the diagonal. Square root of eigenvalues associated with $AA^T$ or $A^TA$ (its the same).<br>$V$ : $m \times m$ : orthogonal matrix containing eigenvectors of $A^TA$.</p>
<p><em>Orthogonal matrix</em>: square matrix where columns make $90^\circ$ angles between each other and its inner dot product is zero. $Q^TQ = QQ^T = I$ and $Q^T=Q^{-1}$.<br><em>Orthonormal matrix</em>: orthogonal matrix where columns are unit vectors.</p>
<h2 id="Example_matrix">Example matrix</h2><p>For this post, Im going to use the same matrices from <a href="http://scriptogr.am/alyssa/post/understanding-eigenvectors-and-eigenvalues-visually" target="_blank" rel="external">my post on eigenvectors and eigenvalues</a>. We have a matrix $x = \begin{bmatrix}<br>-10 &amp; -10 &amp; 20 &amp; 20\\<br>-10 &amp; 20 &amp; 20 &amp; -10<br>\end{bmatrix}$ and a transformation matrix $A = \begin{bmatrix}<br>1 &amp; 0.3 \\<br>0.45 &amp; 1.2<br>\end{bmatrix}$. In the plot below, the dashed square shows $x$ as the corners and the transformed matrix $Ax$ as the solid shape.</p>
<p><img src="https://alyssaq.github.io/blog/images/eigens-transformation_matrix.png" alt="transformed_plot"></p>
<p>Python’s numpy provides us with a handy <a href="http://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.svd.html" target="_blank" rel="external"><code>svd</code></a> function:</p>
<pre><code class="language-python">
In[1]:
A = np.matrix([[1, 0.3], [0.45, 1.2]])
U, s, V = np.linalg.svd(A)

Out[1]:
U:[[-0.58189652 -0.81326284]
   [-0.81326284  0.58189652]]
s:[ 1.49065822  0.71444949]
V:[[-0.63586997 -0.77179621]
   [-0.77179621  0.63586997]]
</code></pre>

<p>Lets verify some properties of the SVD matrices.</p>
<pre><code class="language-python">
# Verify calculation of A=USV
In[2]:  np.allclose(A, U * np.diag(s) * V)
Out[2]: True

# Verify orthonormal properties of U and V. (Peformed on U but the same applies for V).
#  1) Dot product between columns = 0
In[3]:  np.round([np.dot(U[:, i-1].A1,  U[:, i].A1) for i in xrange(1, len(U))])
Out[3]: [ 0. 0.]

#  2) Columns are unit vectors (length = 1)
In[4]:  np.round(np.sum((U*U), 0))
Out[4]: [[ 1.  1.  1.]]

#  3) Multiplying by its transpose = identity matrix
In[5]:  np.allclose(U.T * U, np.identity(len(U)))
Out[5]: True
</code></pre>

<h2 id="Geometric_interpretation_of_SVD">Geometric interpretation of SVD</h2><p>Transformation of a matrix by $U S V^T$ can be visualised as a <em>rotation and reflection</em>, <em>scaling</em>, <em>rotation and reflection</em>. We’ll see this as a step-by-step visualisation.</p>
<h4 id="(1)_$V^Tx$">(1) $V^Tx$</h4><p>We can see that multiplying by $V^T$ rotates and reflects the input matrix $x$. Notice the swap of colours red-blue and green-yellow indicating a reflection along the x-axis.<br><img src="https://alyssaq.github.io/blog/images/svd_Vx.png" alt="Vx_plot"></p>
<h4 id="(2)_$SV^Tx$">(2) $SV^Tx$</h4><p>Since $S$ only contains values on the diagonal, it simply scales the matrix. The singular values $S$ are ordered in descending order so $s_1 &gt; s_2 &gt; … &gt; s_n$. $V$ rotates the matrix to a position where the singular values now represent the scaling factor along the x and y-axis. This is now the <em>V-basis</em>.</p>
<p>The black dots shows this ($V^Tx$ is dashed and $SV^Tx$ solid):</p>
<ul>
<li>$V^Tx$ intercepts the x-axis at $x = -25.91$.</li>
<li>Largest singular value of $s_1 = 1.49$ is applied and $s_1x = -38.61$.</li>
<li>$V^Tx$ intercepts the y-axis at $y = 12.96$.</li>
<li>Smallest singular value of $s_2 = 0.71$ is applied and $s_2y = 9.20$.</li>
</ul>
<p><img src="https://alyssaq.github.io/blog/images/svd_SVx.png" alt="SVx_plot"></p>
<p>While not shown, there is a similar rotation and scaling effect in the <em>U-basis</em> with $Ux$ and $SUx$.</p>
<h4 id="(3)_$USV^Tx$">(3) $USV^Tx$</h4><p>Finally, $U$ rotates and reflects the matrix back to the standard basis. As expected, this is exactly the same as $Ax$.</p>
<p><img src="https://alyssaq.github.io/blog/images/svd_USVx.png" alt="USVx_plot"></p>
<h2 id="Eigen_decomposition_vs_singular_value_decomposition">Eigen decomposition vs singular value decomposition</h2><p>In an eigen-decomposition, $A$ can be represented by a product of its eigenvectors $Q$ and diagonalised eigenvalues $\Lambda$:<br> $$ A = Q \Lambda Q^{-1}$$.</p>
<ul>
<li>Unlike an eigen-decomposition where the matrix must be square ($n \times n$), SVD can decompose a matrix of any dimension.</li>
<li>Column vectors in $Q$ are not always orthogonal so the change in basis is not a simple rotation. $U$ and $V$ are orthogonal and always represent rotations (and reflections).</li>
<li>Singular values in $S$ are all real and non-negative. The eigenvalues in $\Lambda$ can be complex and have imaginary numbers.</li>
</ul>
<h2 id="Resources">Resources</h2><p>SVD ties together the core concepts of linear algebra — matrix transformations, projections, subspaces, change of basis, eigens, symmetric matrices, orthogonalisation and factorisation. For a complete proof and backgound, I highly recommend the entire <a href="http://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/" target="_blank" rel="external">MIT Linear Algebra lectures by Gilbert Strang</a>. I also found the examples and proofs for SVD and QR factorisation from the <a href="http://www.ulaff.net" target="_blank" rel="external">University of Texas’ MOOC</a> useful.</p>
<p>Other posts covering SVD visualisations and its applications:</p>
<ul>
<li><a href="http://www.ams.org/samplings/feature-column/fcarc-svd" target="_blank" rel="external">http://www.ams.org/samplings/feature-column/fcarc-svd</a></li>
<li><a href="http://neurochannels.blogspot.sg/2008/02/visualizing-svd.html" target="_blank" rel="external">http://neurochannels.blogspot.sg/2008/02/visualizing-svd.html</a></li>
<li><a href="http://www.math.umn.edu/~lerman/math5467/svd.pdf" target="_blank" rel="external">http://www.math.umn.edu/~lerman/math5467/svd.pdf</a></li>
<li><a href="http://www.mathworks.com/company/newsletters/articles/professor-svd.html" target="_blank" rel="external">http://www.mathworks.com/company/newsletters/articles/professor-svd.html</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p><a href="https://books.google.com.sg/books?id=MjNwWUY8jx4C&amp;pg=PA259" target="_blank" rel="external">“The SVD is absolutely a high poi]]>
    </summary>
    
      <category term="computer vision" scheme="alyssaq.github.io/tags/computer-vision/"/>
    
      <category term="linear algebra" scheme="alyssaq.github.io/tags/linear-algebra/"/>
    
      <category term="python" scheme="alyssaq.github.io/tags/python/"/>
    
      <category term="data science" scheme="alyssaq.github.io/categories/data-science/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Computing the Axes or Orientation of a Blob]]></title>
    <link href="alyssaq.github.io/2015/computing-the-axes-or-orientation-of-a-blob/"/>
    <id>alyssaq.github.io/2015/computing-the-axes-or-orientation-of-a-blob/</id>
    <published>2015-01-13T19:30:00.000Z</published>
    <updated>2015-10-18T08:46:22.000Z</updated>
    <content type="html"><![CDATA[<h4 id="How_do_we_find_the_major_and_minor_axes_of_a_blob?">How do we find the major and minor axes of a blob?</h4><p>We look at using 2 popular methods to obtain the same result:</p>
<ol>
<li>Covariance matrix and eigenvectors, eigenvalues (partial PCA).</li>
<li>Raw image moments</li>
</ol>
<h2 id="1-_Covariance_matrix_and_eigens">1. Covariance matrix and eigens</h2><p>An <strong>eigenvalue</strong> tells us the scaling magnitude along the direction of its corresponding <strong>eigenvector</strong>. Check my post on <a href="http://scriptogr.am/alyssa/post/understanding-eigenvectors-and-eigenvalues-visually" target="_blank" rel="external">understanding eigens</a> for the visual intuition. </p>
<p><a href="http://mathworld.wolfram.com/CovarianceMatrix.html" target="_blank" rel="external"><strong>Covariance matrix</strong></a> is a square and symmetric matrix that summarises the variance between two variables. So, with a set of $(x, y)$ points, the covariance matrix is 2x2:<br>$ C = \begin{bmatrix}<br>variance(x,x) &amp; variance(x,y) \\<br>variance(x,y) &amp; variance(y,y)<br>\end{bmatrix}$, where the variance of $(x, y)$ and $(y, x)$ are the same.</p>
<p><strong>Principal component analysis (PCA)</strong> is a method commonly used for dimensionality reduction. The eigenvectors of the covariance matrix are called <strong>principal components</strong>. Heres a thorough <a href="http://www.cs.otago.ac.nz/cosc453/student_tutorials/principal_components.pdf" target="_blank" rel="external">tutorial on PCA and applied to computer vision (Lindsay Smith, 2002)</a>.</p>
<p><strong>Eigenvectors with the largest eigenvalue of a covariance matrix</strong> gives us the direction along which the data has the largest variance.</p>
<h3 id="Computation_Outline">Computation Outline</h3><ol>
<li><strong>Matrix of points</strong>. We’ll be dealing with 2D points so our matrix is 2x<em>m</em>. The 1st row are the x-coordinates, 2nd row are the y-coordinates and <em>m</em> indicates the number of points.</li>
<li><strong>Subtract the mean for each point</strong>. Calculate the mean of the row of x-coordinates. For each x-point, subtract the mean from it. Do the same for the y-coordinates. Mean subtraction minimises the mean square error of approximating the data and centers the data.</li>
<li><strong>Covariance matrix calculation</strong>. Calculate the 2x2 covariance matrix.</li>
<li><strong>Eigenvectors, eigenvalues of covariance matrix</strong>. Find the 2 eigen-pairs of our dataset.</li>
<li><strong>Rearrange the eigen-pairs</strong>. Sort by decreasing eigenvalues.</li>
<li><strong>Plot the principal components</strong></li>
</ol>
<p>Steps 1-5 are the beginning crux to performing <a href="http://en.wikipedia.org/wiki/Principal_component_analysis#Computing_PCA_using_the_covariance_method" target="_blank" rel="external">dimensionality reduction with PCA</a>.</p>
<h3 id="Code_Time">Code Time</h3><p>We’ll use a binary image as input and our matrix of points are the indices to the white pixels. Heres the image:</p>
<p style="text-align:center"><br><img src="https://alyssaq.github.io/blog/images/blob_axes-skewed_oval.png"><br></p>

<p>First, the libraries we’ll be using:</p>
<pre><code class="language-python">
import numpy as np
import matplotlib.pyplot as plt
import scipy.misc
import skimage.filter
</code></pre>

<p><strong>1) Read the image in grey-scale.</strong> We want the indexes of the white pixels to find the axes of the blob.</p>
<pre><code class="language-python">
img = misc.imread('oval.png', flatten=1)
y, x = np.nonzero(img)
</code></pre>

<p><strong>2) Subtract mean from each dimension.</strong> We now have our 2x<em>m</em> matrix.</p>
<pre><code class="language-python">
x = x - np.mean(x)
y = y - np.mean(y)
coords = np.vstack([x, y])
</code></pre>

<p><strong>3 &amp; 4) Covariance matrix and its eigenvectors and eigenvalues</strong></p>
<pre><code class="language-python">
cov = np.cov(coords)
evals, evecs = np.linalg.eig(cov)
</code></pre>

<p><strong>5) Sort eigenvalues in decreasing order</strong> (we only have 2 values)</p>
<pre><code class="language-python">
sort_indices = np.argsort(evals)[::-1]
evec1, evec2 = evecs[:, sort_indices]
x_v1, y_v1 = evec1  # Eigenvector with largest eigenvalue
x_v2, y_v2 = evec2
</code></pre>

<p><strong>6) Plot the principal components.</strong> The larger eigenvector is plotted in red and drawn twice as long as the smaller eigenvector in blue.</p>
<pre><code class="language-python">
scale = 20
plt.plot([x_v1*-scale*2, x_v1*scale*2], 
         [y_v1*-scale*2, y_v1*scale*2], color='red')
plt.plot([x_v2*-scale, x_v2*scale], 
         [y_v2*-scale, y_v2*scale], color='blue')
plt.plot(x, y, 'k.')
plt.axis('equal')
plt.gca().invert_yaxis()  # Match the image system with origin at top left
plt.show()
</code></pre>

<p style="text-align:center"><br><img src="https://alyssaq.github.io/blog/images/blob_axes-eigens_plot.png"><br></p>

<p><strong>7) Bonus!</strong> We vertically-align the blob based on the major axis via a linear transformation. An <a href="scriptogr.am/alyssa/post/visualising-matrices-and-affine-transformations-with-python#rotating">anti-clockwise rotating transformation matrix</a> has the general form:<br>$\begin{bmatrix}<br>cos \theta &amp; -sin \theta \\<br>sin \theta &amp; cos \theta<br>\end{bmatrix}$.</p>
<p>To do this:</p>
<ol>
<li>Calculate $\theta$ using the eigenvector of the major axis to the y-axis</li>
<li>Create the rotating transformation matrix</li>
<li>Multiply the transformation matrix to the set of coordinates.<pre><code class="language-python">
theta = np.tanh((x_v1)/(y_v1))  
rotation_mat = np.matrix([[np.cos(theta), -np.sin(theta)], 
                      [np.sin(theta), np.cos(theta)]])
transformed_mat = rotation_mat * coords
# plot the transformed blob
x_transformed, y_transformed = transformed_mat.A
plt.plot(x_points, y_points, 'g.')
</code></pre>

</li>
</ol>
<p>The vertically-align transformed blob is overlaid in green.</p>
<p style="text-align:center"><br><img src="https://alyssaq.github.io/blog/images/blob_axes-transformed_plot.png"><br></p>

<h2 id="2-_Raw_image_moments">2. Raw image moments</h2><p>We can obtain the same axes and orientation of a blob with <a href="http://en.wikipedia.org/wiki/Image_moment#Raw_moments" target="_blank" rel="external">raw image moments and central moments</a>. Special thanks to this <a href="http://stackoverflow.com/questions/9005659/compute-eigenvectors-of-image-in-python" target="_blank" rel="external">stack overflow answer</a>.</p>
<p>The calculation of a raw image moment is given by the equation:<br>$$<br>M<em>{ij} = \sum\limits</em>{y=0}^{nrows}\sum\limits_{x=0}^{ncols} x^i \ y^j \ I(x, y)<br>$$ where $x$ and $y$ are indices to the data and $I(x, y)$ is the grey-level intensity value at that index. The codification of that equation:</p>
<pre><code class="language-python">
def raw_moment(data, i_order, j_order):
  nrows, ncols = data.shape
  y_indices, x_indicies = np.mgrid[:nrows, :ncols]
  return (data * x_indicies**i_order * y_indices**j_order).sum()
</code></pre>

<p>Now we can derive the second order central moments and construct its covariance matrix:</p>
<pre><code class="language-python">
def moments_cov(data):
  data_sum = data.sum()
  m10 = raw_moment(data, 1, 0)
  m01 = raw_moment(data, 0, 1)
  x_centroid = m10 / data_sum
  y_centroid = m01 / data_sum
  u11 = (raw_moment(data, 1, 1) - x_centroid * m01) / data_sum
  u20 = (raw_moment(data, 2, 0) - x_centroid * m10) / data_sum
  u02 = (raw_moment(data, 0, 2) - y_centroid * m01) / data_sum
  cov = np.array([[u20, u11], [u11, u02]])
  return cov
</code></pre>

<p>Note that calculating the image moments does not require finding the indices to the blob shape. To use the above function, simply call it with the image data:</p>
<pre><code class="language-python">
img = misc.imread('oval.png', flatten=1)
cov = moments_cov(img)
evals, evecs = np.linalg.eig(cov)
</code></pre>

<p>Given the covariance matrix, finding the axes and re-aligning the blob continues with steps 4 to 7 from the first method. As expected, the transformed plot looks the same:</p>
<p style="text-align:center"><br><img src="https://alyssaq.github.io/blog/images/blob_axes-moments_plot.png"><br></p>


<h2 id="Comparison">Comparison</h2><p>In this case, using image moments would be faster since we do not have to find the $(x, y)$ coordinates to the blob pixels. Both methods would encounter issues with images containing lots of noise.</p>
<p>The partial PCA calculated the largest eigenvalue of 2942.0060 and its eigenvector [0.3997, -0.9166]. By a slight difference, image moments returned the largest eigenvalue of calculated the largest eigenvalue of 2943.2583 and its eigenvector of [0.4027, -0.9153].<br>Their $\theta$ difference is less than a fifth of $1^\circ$.</p>
<p>For asymmetric blobs, both methods will be biased to the side that has the higher concentration of pixels. Heres an image where the axes appear to be slightly off and over-rotates in an attempt to align it (original image on the left):</p>
<p><img src="https://alyssaq.github.io/blog/images/blob_axes-three_plot.png" alt="three_plot"></p>
]]></content>
    <summary type="html">
    <![CDATA[<h4 id="How_do_we_find_the_major_and_minor_axes_of_a_blob?">How do we find the major and minor axes of a blob?</h4><p>We look at using 2 pop]]>
    </summary>
    
      <category term="computer vision" scheme="alyssaq.github.io/tags/computer-vision/"/>
    
      <category term="linear algebra" scheme="alyssaq.github.io/tags/linear-algebra/"/>
    
      <category term="python" scheme="alyssaq.github.io/tags/python/"/>
    
      <category term="data science" scheme="alyssaq.github.io/categories/data-science/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Understanding Eigenvectors and Eigenvalues Visually]]></title>
    <link href="alyssaq.github.io/2015/understanding-eigenvectors-and-eigenvalues-visually/"/>
    <id>alyssaq.github.io/2015/understanding-eigenvectors-and-eigenvalues-visually/</id>
    <published>2015-01-07T07:30:00.000Z</published>
    <updated>2015-10-18T08:46:11.000Z</updated>
    <content type="html"><![CDATA[<p>Eigenvectors and eigenvalues are used in many engineering problems and have applications in <a href="http://www.cipa.dcu.ie/papers/spie_97.pdf" target="_blank" rel="external">object recognition</a>, <a href="http://cg.cs.uni-bonn.de/fileadmin/Downloads/schultz/papers/schultz-evalder-2008.pdf" target="_blank" rel="external">edge detection in diffusion MRI images</a>, <a href="http://www2.eng.cam.ac.uk/~hemh/gyroscopes/momentinertia.html" target="_blank" rel="external">moments of inertia</a> in motor calculations, <a href="http://www.ma.utexas.edu/mp_arc/c/13/13-25.pdf" target="_blank" rel="external">bridge modelling</a>, <a href="http://www.rose-hulman.edu/~bryan/googleFinalVersionFixed.pdf" target="_blank" rel="external">Google’s PageRank algorithm</a> and more on <a href="http://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors#Applications" target="_blank" rel="external">wikipedia</a>.</p>
<p>Previously, I wrote about <a href="http://scriptogr.am/alyssa/post/visualising-matrices-and-affine-transformations-with-python" target="_blank" rel="external">visualising matrices and affine transformations</a>. Here, we build on top of that and understand eigenvectors and eigenvalues visually.</p>
<h2 id="Interpreting_eigens">Interpreting eigens</h2><p>Quick recap, a non-zero matrix $x$ can be transformed by multiplying it with a $n \times n$ square matrix, $A$. So, the transformed matrix can be represented by the equation:<br>$$ T(x) = Ax $$</p>
<p>$x$ is called an <strong>eigenvector</strong> that when multiplied with $A$, yields a scalar value, $\lambda$, called the <strong>eigenvalue</strong>. The basic equation is:<br>$$ Ax = \lambda x $$</p>
<p>Any vector $v$ on the line made from the points passing through the origin $(0,0)$ and an eigenvector are all eigenvectors. Transforming $v$ by multiplying it by the transformation matrix $A$ or its associated eigenvalue $\lambda$ will result in the same vector. This will make more sense with the visuals in the following sections.</p>
<p>Most libraries (including numpy) will return eigenvectors that have been scaled to have a length of 1 (called <em>unit vectors</em>).</p>
<p>Eigenvalue $\lambda$ tells us how much $x$ is scaled, stretched, shrunk, reversed or untouched when multiplied by $A$. The number of eigenvalues is at most the number of dimensions, $n$. So, a set of 2D vectors will have at most 2 eigenvalues and corresponding eigenvectors.</p>
<h2 id="Calculating_eigenvalues,_eigenvectors">Calculating eigenvalues, eigenvectors</h2><p>Eigenvalue $\lambda$ and its corresponding eigenvector is found by solving the equation: $$det(\lambda I - A) = 0$$</p>
<p><strong>What does determinant zero mean?</strong><br>Heres a nice <a href="http://www.math.harvard.edu/~elkies/M21b.08/det.html" target="_blank" rel="external">factsheet of determinant properties</a>. If the $det(M) = 0$, $M$ is not invertible (columns cannot be swapped) and the rows and columns of $M$ are linearly dependent (one of the vectors in the set can be represented by the others. E.g {[2, 3], [4, 6]} are dependent as the second vector is a scaled version of the first vector in the set.)</p>
<p>You should watch Khan Academy’s <a href="https://www.khanacademy.org/math/linear-algebra/alternate_bases/eigen_everything/v/linear-algebra-example-solving-for-the-eigenvalues-of-a-2x2-matrix" target="_blank" rel="external">example solving eigenvalues</a> and the entire <em>Eigen-eveything</em> series if you want a step-by-step calculation and cement the maths. I also found these resources useful: </p>
<ul>
<li><a href="http://www.math.msu.edu/~shapiro/Teaching/classes/311UH_05/Eigenvalues.pdf" target="_blank" rel="external">Coordinates, Eigenvalues, and Eigenvectors (Michigan State University)</a></li>
<li><a href="http://math.mit.edu/~gs/linearalgebra/ila0601.pdf" target="_blank" rel="external">Introduction to Linear Algebra, 4th ed, Chapter 6</a>.</li>
<li><a href="https://www.youtube.com/watch?v=lXNXrLcoerU" target="_blank" rel="external">Prof Gilbert Strang’s Eigenvalues and Eigenvectors lecture at MIT</a></li>
</ul>
<h2 id="Eigens_of_a_scaling_transformation_matrix">Eigens of a scaling transformation matrix</h2><p>Lets start with a simple transformation matrix, $A = \begin{bmatrix}<br>2 &amp; 0 \\<br>0 &amp; 3<br>\end{bmatrix}$.  </p>
<pre><code class="language-python">
In [1]: A = np.matrix([[2, 0], [0, 3]])
In [2]: evals, evecs = np.linalg.eig(A)

Out[2]: evals:  [ 2.  3.]
        evecs: [[ 1.  0.]
                [ 0.  1.]]
</code></pre>

<p>The first eigenvalue, 2, is associated with the eigenvector in the first column (1, 0). Equation of the line through $(0,0)$ and $(1,0)$ is $y = 0$. So, any point on this line when multiplied by the transformation matrix $A$, will be scaled by 2.</p>
<p>Similarly, for the second eigenvalue, any point on the line $x = 0$ will be scaled by 3.</p>
<h2 id="Visualising_eigenvalues_and_eigenvectors">Visualising eigenvalues and eigenvectors</h2><p>Lets use a more involved transformation matrix $A = \begin{bmatrix}<br>1 &amp; 0.3 \\<br>0.45 &amp; 1.2<br>\end{bmatrix}$.</p>
<p>For visualisation, we’ll plot a matrix $x = \begin{bmatrix}<br>-10 &amp; -10 &amp; 20 &amp; 20\\<br>-10 &amp; 20 &amp; 20 &amp; -10<br>\end{bmatrix}$ and its transformed state after it has been multiplied with $A$.</p>
<p><img src="https://alyssaq.github.io/blog/images/eigens-transformation_matrix.png" alt="transformed_plot"></p>
<p>The dashed square shows the original matrix $x$ and the transformed matrix $Ax$. Now we’ll see where the eigens come into play.</p>
<pre><code class="language-python">
In [1]: A = np.matrix([[1, 0.3], [0.45, 1.2]])
In [2]: evals, evecs = np.linalg.eig(A)

Out[2]: evals:  [ 0.71921134  1.48078866]
        evecs: [[-0.73009717 -0.52937334]
                 [ 0.68334334 -0.84838898]] 
</code></pre>

<p>To plot the eigenvectors, we calculate the gradient:</p>
<pre><code class="language-python">
In [1]: x_v1, y_v1 = evecs[:,0].getA1()
        x_v2, y_v2 = evecs[:,1].getA1()
In [2]: m1 = y_v1/x_v1 # Gradient of 1st eigenvector
        m2 = y_v2/x_v2 # Gradient of 2nd eigenvector    

Out [2]: m1 = -0.936, m2 = 1.603  # Round to 3dp
</code></pre>

<p>So, our eigenvectors, which span all vectors along the line through the origin, have the equations: $y = -0.936x$ ($e1$) and $y = 1.603x$ ($e2$). This is plotted in blue and red below.</p>
<p><img src="https://alyssaq.github.io/blog/images/eigens-eigenvector_plot.png" alt="eigenvectors_plot"></p>
<p><strong>What does this eigen plot tell us?</strong><br>The point where the first eigenvector line $e1$ intercepts the original matrix is $p1 = (10.68, -10)$. Multiplying this point by the corresponding eigenvalue of 0.719 OR by the transformation matrix $A$, yields $T(p1) = (7.684, -7.192)$.</p>
<p>$$ \begin{equation}<br>\begin{aligned}<br>A \times p1 \ &amp;=<br>\begin{bmatrix}<br>1 &amp; 0.3 \\<br>0.45 &amp; 1.2<br>\end{bmatrix} &amp; \times \begin{bmatrix}<br>10.68 \\<br>-10<br>\end{bmatrix} &amp;= \begin{bmatrix}<br>7.684 \\<br>-7.192<br>\end{bmatrix} \\<br>\lambda \times p1 \ &amp;=<br>0.719 &amp; \times \begin{bmatrix}<br>10.68 \\<br>-10<br>\end{bmatrix} &amp;=<br>\begin{bmatrix}<br>7.684 \\<br>-7.192<br>\end{bmatrix} \\<br>\end{aligned}<br>\end{equation} \\<br>\therefore Ax = \lambda x $$    </p>
<p>Doing this for $e2$ will show the same calculation. As this eigenvector is associated with the largest eigenvalue of 1.481, this is the maximum possible stretch when acted by the transformation matrix. </p>
<p>To complete the visuals, we’ll plot $p1$ (the intercept with $e1$), $p2$ (the intercept with $e2$) and their transformed point $T(p1)$ and $T(p2)$.<br><a href="https://gist.github.com/alyssaq/f56ba93b4d3b3be76943" target="_blank" rel="external"><i class="fa fa-github-alt"></i> Gist for the full plot</a><br><img src="https://alyssaq.github.io/blog/images/eigens-full_plot.png" alt="full_plot"></p>
<h2 id="Eigendecomposition"><a href="#eigendecomposition">Eigendecomposition</a></h2><p>We can rearrange $Ax = \lambda x$ to represent $A$ as a product of its eigenvectors and eigenvalues by diagonalising the eigenvalues:<br>$$A = Q \Lambda Q^{-1}$$<br>with $Q$ as the eigenvectors and $\Lambda$ as the diagonalised eigenvalues. Using the values from the example above:</p>
<p>$$ \begin{bmatrix}<br>1 &amp; 0.3 \\<br>0.45 &amp; 1.2<br>\end{bmatrix} =<br>\begin{bmatrix}<br>-0.730 &amp; -0.529 \\<br>0.683 &amp; -0.848<br>\end{bmatrix}<br>\begin{bmatrix}<br>0.719 &amp; 0 \\<br>0 &amp; 1.481<br>\end{bmatrix}<br>\begin{bmatrix}<br>-0.730 &amp; -0.529 \\<br>0.683 &amp; -0.848<br>\end{bmatrix}^{-1} $$</p>
<p>To check this in Python:</p>
<pre><code class="language-python">
In [1]: A = np.matrix([[1, 0.3], [0.45, 1.2]])
In [2]: evals, evecs = np.linalg.eig(A)
In [3]: np.allclose(A, evecs * np.diag(evals) * np.linalg.inv(evecs))
Out[3]: True
</code></pre>

<p>Next up, we’ll connect the eigen decomposition to another super useful technique, the singular value decomposition.</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>Eigenvectors and eigenvalues are used in many engineering problems and have applications in <a href="http://www.cipa.dcu.ie/papers/spie_9]]>
    </summary>
    
      <category term="computer vision" scheme="alyssaq.github.io/tags/computer-vision/"/>
    
      <category term="linear algebra" scheme="alyssaq.github.io/tags/linear-algebra/"/>
    
      <category term="python" scheme="alyssaq.github.io/tags/python/"/>
    
      <category term="data science" scheme="alyssaq.github.io/categories/data-science/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Visualising Matrices and Affine Transformations With Python]]></title>
    <link href="alyssaq.github.io/2015/visualising-matrices-and-affine-transformations-with-python/"/>
    <id>alyssaq.github.io/2015/visualising-matrices-and-affine-transformations-with-python/</id>
    <published>2015-01-01T18:00:00.000Z</published>
    <updated>2015-10-18T09:01:15.000Z</updated>
    <content type="html"><![CDATA[<p>Here, we visualise matrix linear and affine transformations to set the foundation in understanding more awesome computer vision techniques (still a learning process for me). </p>
<p>There is an assumed knowledge of the core mathematical concepts in matrices and vectors. If a refresher is needed, I highly recommend <a href="https://www.khanacademy.org/math/precalculus" target="_blank" rel="external">Khan Academy’s Precalculus</a> course.</p>
<p>I also recommend <a href="https://www.khanacademy.org/math/linear-algebra" target="_blank" rel="external">Khan Academy’s Linear Algebra</a> course for further learning. </p>
<h2 id="Linear_vs_Affine_transform">Linear vs Affine transform</h2><p>Quick distinction. Linear transformations are fixed around the origin (scaling, rotating, skewing). Affine transformations are a linear function followed by a translation.</p>
<h2 id="Visualising_a_matrix">Visualising a matrix</h2><p>Points in 2D space can be written as (3, 13), (5, 15). A set of 2D vectors can be written in a matrix as<br>$\begin{bmatrix}<br>3 &amp; 5 \\<br>13 &amp; 15<br>\end{bmatrix}$<br>with each column representing a data point.<br>So, a matrix, say $P$ =<br>$\begin{bmatrix}<br>0 &amp; 0 &amp; 20 &amp; 20\\<br>0 &amp; 20 &amp; 20 &amp; 0<br>\end{bmatrix}$ consists of 4 points. Lets plot it in Python.</p>
<p>First, the libraries:</p>
<pre><code class="language-python">
import numpy as np
import matplotlib.pyplot as plt
</code></pre>

<p>I’m going to draw a line between the points but you should picture the line as a row of many points. Heres the function to plot the matrix that will be reused throughout this post:</p>
<pre><code class="language-python">
def plot_points(matrix, ls='--', lw=1.2, colors=None):
  x_points, y_points = matrix
  size = len(x_points)
  colors = ['red', 'blue', 'orange', 'green'] if not None else colors
  for i in range(size):
    plt.plot(x_points[i], y_points[i], color=colors[i], marker='o')
    plt.plot([x_points[i], x_points[(i+1) % size]], 
             [y_points[i], y_points[(i+1) % size]], 
             color=colors[i], 
             linestyle=ls, linewidth=lw)
</code></pre>

<p>Now, we plot our matrix, $P$.</p>
<pre><code class="language-python">
x_points = np.array([0, 0, 20, 20])
y_points = np.array([0, 20, 20, 0])
matrix = np.array([x_points, y_points])
colors = ['red', 'blue', 'orange', 'green']
size = len(x_points)
plot_points(matrix, colors)
plt.ylim([-5,25])
plt.xlim([-5,25])
plt.axes().set_aspect('equal')
plt.show()
</code></pre>

<p>And our matrix $P$ =<br>$\begin{bmatrix}<br>0 &amp; 0 &amp; 20 &amp; 20\\<br>0 &amp; 20 &amp; 20 &amp; 0<br>\end{bmatrix}$ can be visualised as the corners of a square. Remember to view the lines as a bunch of points.</p>
<p style="text-align:center"><br><img src="https://alyssaq.github.io/blog/images/matrix-plot.png"><br></p>

<h2 id="Identity_matrix">Identity matrix</h2><p>Multiplying a matrix with the identity matrix does nothing to the matrix. That is, $\begin{bmatrix} 1 &amp; 0 \\ 0 &amp; 1 \end{bmatrix}<br>\begin{bmatrix} 3 \\ 13 \end{bmatrix} = \begin{bmatrix} 3 \\ 13 \end{bmatrix}$. Each column in the indentity matrix are called <a href="http://en.wikipedia.org/wiki/Basis_%28linear_algebra%29" target="_blank" rel="external"><em>basis vectors</em></a> (linearly independent and equations solve for 0). These will be super useful in deriving and visualising the transformation matrices.</p>
<h2 id="Scaling">Scaling</h2><p><img src="https://alyssaq.github.io/blog/images/matrix-scaling.png" style="float:left"><br>Lets say we want to scale our points by 2. The plot on the left shows the identity matrix in black and our end goal in red. Heres the <a href="https://gist.github.com/alyssaq/90d5f116250c443cd928#file-plot_matrix_scaling-py" target="_blank" rel="external">github gist</a> for the plot. The first vector along the <em>x</em>-axis, $\begin{bmatrix} 1 \\ 0 \end{bmatrix}$ has to be multipled by 2 to get to $\begin{bmatrix} 2 \\ 0 \end{bmatrix}$. The same is applied to the second vector along the <em>y</em>-axis.  Our end matrix is $\begin{bmatrix} 2 &amp; 0 \\ 0 &amp; 2 \end{bmatrix}$. </p>
<p>To generalise, we can multiply a matrix by $\begin{bmatrix} k1 &amp; 0 \\ 0 &amp; k2 \end{bmatrix}$ to achieve scaling in 2D space. $k1$ and $k2$ can be the same or different to obtain different scalings in the different dimensions.</p>
<p><img src="https://alyssaq.github.io/blog/images/matrix-scaling-result.png" style="float:right"></p>
<p>Lets try scaling our matrix $P$ by multiplying it with the matrix:<br>$\begin{bmatrix}<br>1.5 &amp; 0 \\<br>0 &amp; 2<br>\end{bmatrix}$  As expected, we can see that the original square (dashed lines) has been scaled by 1.5 in the positive <em>x</em> direction and scaled by 2 in the positive <em>y</em> direction.</p>
<p>The resultant matrix is:<br>$\begin{bmatrix}<br>1.5 &amp; 0 \\<br>0 &amp; 2<br>\end{bmatrix} \times<br>\begin{bmatrix}<br>0 &amp; 0 &amp; 20 &amp; 20\\<br>0 &amp; 20 &amp; 20 &amp; 0<br>\end{bmatrix} =<br>\begin{bmatrix}<br>0 &amp; 0 &amp; 30 &amp; 30\\<br>0 &amp; 40 &amp; 40 &amp; 0<br>\end{bmatrix}$</p>
<h2 id="Reflecting">Reflecting</h2><p>We can reflect the points along the <em>y</em>-axis by multiplying all <em>x</em> coordinates by -1. So, $(1, 1)$ becomes $(-1, 1)$. That means we can multiply a matrix by $\begin{bmatrix}<br>-1 &amp; 0 \\<br>0 &amp; 1<br>\end{bmatrix}$ and it’ll mirror along the <em>y</em>-axis. And the visuals!</p>
<p style="text-align:center"><img src="https://alyssaq.github.io/blog/images/matrix-reflection-result.png"></p> 

<h2 id="Skewing">Skewing</h2><p>Lets skew the identity matrix by +50%. The vector along the <em>x</em>-axis stays the same while the vector along the <em>y</em>-axis shifts <em>k</em> = 0.5 to the right. Our resultant matrix is now $\begin{bmatrix}<br>1 &amp; 0.5 \\<br>0 &amp; 1<br>\end{bmatrix}$ and a skewing transformation matrix can be generalised as $\begin{bmatrix}<br>1 &amp; k \\<br>0 &amp; 1<br>\end{bmatrix}$.</p>
<p>So, doing<br>$\begin{bmatrix}<br>1 &amp; 0.5 \\<br>0 &amp; 1<br>\end{bmatrix} \times<br>\begin{bmatrix}<br>0 &amp; 0 &amp; 20 &amp; 20\\<br>0 &amp; 20 &amp; 20 &amp; 0<br>\end{bmatrix}$<br>will skew $P$ by 50%.</p>
<p style="text-align:center"><img src="https://alyssaq.github.io/blog/images/matrix-skewing-result.png"></p> 

<h2 id="Rotating"><a name="rotating"></a> Rotating</h2><p><img src="https://alyssaq.github.io/blog/images/matrix-rotating.png" style="float:left"><br>My favourite linear transformation. Using the trusty <a href="http://www.mathsisfun.com/algebra/sohcahtoa.html" target="_blank" rel="external"><em>SOH CAH TOA</em></a> acronym, we can see that<br>(1, 0) on the <em>x</em>-axis lands on $(cos \theta, sin \theta)$ and<br>(0, 1) on the <em>y</em>-axis lands on $(-sin \theta, cos \theta)$ when rotated by positive $\theta$. </p>
<p>Thus, our rotating transformation matrix has the general form: $\begin{bmatrix}<br>cos \theta &amp; -sin \theta \\<br>sin \theta &amp; cos \theta<br>\end{bmatrix}$. </p>
<p>Lets plot $P$ when it is rotated by $-30^\circ$. Note the change in negative $sin$ for clockwise rotation. Our matrices involved in this transformation are:</p>
<p>$\begin{bmatrix}<br>0.866 &amp; 0.5 \\<br>-0.5 &amp; 0.866<br>\end{bmatrix} \times<br>\begin{bmatrix}<br>0 &amp; 0 &amp; 20 &amp; 20\\<br>0 &amp; 20 &amp; 20 &amp; 0<br>\end{bmatrix} =<br>\begin{bmatrix}<br>0 &amp; 10 &amp; 27.32 &amp; 17.32\\<br>0 &amp; 17.32 &amp; 7.32 &amp; -10<br>\end{bmatrix}$<br><img src="https://alyssaq.github.io/blog/images/matrix-rotating-result.png"></p>
<h2 id="Translating">Translating</h2><p>Lastly, the affine transform to translate a matrix. To do this, we need to represent a 2-vector $(x, y)$ to a 3-vector $(x, y, 1)$. A translation matrix has the form $\begin{bmatrix}<br>1 &amp; 0 &amp; t1 \\<br>0 &amp; 1 &amp; t2 \\<br>0 &amp; 0 &amp; 1<br>\end{bmatrix}$ where $t1$ and $t2$ translates a vector in the <em>x</em> and <em>y</em> direction. Lets translate $P$ to the left by 75% and downwards by 25%. Unlike the linear transformations where the scalars are multipliers, the affine scalars specify the distance to be translated.</p>
<p>$\begin{bmatrix}<br>1 &amp; 0 &amp; -15 \\<br>0 &amp; 1 &amp; -5 \\<br>0 &amp; 0 &amp; 1<br>\end{bmatrix} \times<br>\begin{bmatrix}<br>0 &amp; 0 &amp; 20 &amp; 20\\<br>0 &amp; 20 &amp; 20 &amp; 0 \\<br>1 &amp; 1 &amp; 1 &amp; 1<br>\end{bmatrix}$</p>
<pre><code class="language-python">
A = np.matrix([[1, 0, -0.75*20], [0, 1, -0.25*20], [0, 0, 1]]) 
P = np.matrix([[0, 0, 20, 20], [0, 20, 20, 0], [1, 1, 1, 1]])   
translated_matrix = A*P 
</code></pre>

<p>translated_matrix:</p>
<pre><code>matrix([[ -<span class="number">0.75</span>,  -<span class="number">0.75</span>,  <span class="number">19.25</span>,  <span class="number">19.25</span>],
        [ -<span class="number">0.25</span>,  <span class="number">19.75</span>,  <span class="number">19.75</span>,  -<span class="number">0.25</span>],
        [  <span class="number">1.</span>  ,   <span class="number">1.</span>  ,   <span class="number">1.</span>  ,   <span class="number">1.</span>  ]])
</code></pre><p><img src="https://alyssaq.github.io/blog/images/matrix-translating-result.png"></p>
<h2 id="Transformation_matrix">Transformation matrix</h2><p>Heres a summary of the transformation matrices (courtesy of <a href="http://en.wikipedia.org/wiki/Transformation_matrix" target="_blank" rel="external">wikipedia</a>). Notice that a 2x2 linear transformation matrix becomes a 3x3 transformation matrix by padding it with 0s and a 1 at the bottom-right corner. </p>
<p>So, for vectors in 3D ($\mathbb{R}^3$) space, its <em>linear</em> transformation matrix is 3x3 and its <em>affine</em> transformation matrix (usually called without the affine) is 4x4 and so on for higher dimensions.<br><img src="http://upload.wikimedia.org/wikipedia/commons/2/2c/2D_affine_transformation_matrix.svg"></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>Here, we visualise matrix linear and affine transformations to set the foundation in understanding more awesome computer vision technique]]>
    </summary>
    
      <category term="computer vision" scheme="alyssaq.github.io/tags/computer-vision/"/>
    
      <category term="linear algebra" scheme="alyssaq.github.io/tags/linear-algebra/"/>
    
      <category term="python" scheme="alyssaq.github.io/tags/python/"/>
    
      <category term="data science" scheme="alyssaq.github.io/categories/data-science/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[2015]]></title>
    <link href="alyssaq.github.io/2015/2015/"/>
    <id>alyssaq.github.io/2015/2015/</id>
    <published>2014-12-31T18:24:00.000Z</published>
    <updated>2015-10-18T08:45:42.000Z</updated>
    <content type="html"><![CDATA[<h2 id="2014_Review">2014 Review</h2><p>Travelled to 10 different countries in Europe with Seb as the rider and myself as the pillion on his motorbike. Fell in love with <a href="https://www.youtube.com/watch?v=P0FPDgKVEtw" target="_blank" rel="external">the Alps</a>. Did 4 trips from Singapore to Malaysia to <a href="https://www.youtube.com/watch?v=dCJ2m0K7rVU" target="_blank" rel="external">hunt waterfalls</a>. The 4th one spanned over 3 days to Cameron Highlands. Skied twice - first at Niseko, Japan; then at Thredbo, Australia. Joined a group of astronomy enthusiasts in Mersing and spent 2 nights engaging in some spectacular stargazing and astrophotography.</p>
<p>Learnt node.js, python’s scipy stack, front-end development, devops, databases, APIs. Read one novel. Freelanced for the year and earned a third of my usual salary from the previous year. </p>
<p>Spend 2 months obsessed over a super nutritious liquid blend, <a href="alyssaquek.blogspot.sg/2014/10/bentoblend-my-diy-soylent.html">bentoblend</a>. I still drink this for breakfast a couple of times a week.</p>
<p>I had various depressing and lonely moments and various liberating and eye-opening moments. My perspective on life changed the most this year and I’ll continue learning and working to my fullest.</p>
<h2 id="Don’t_just_do,_understand">Don’t just do, understand</h2><p>Learning college/university mathematics was hard. I remember being bogged down by the mathematical symbols and definitions. I had memorised the process of solving equations without understanding how it worked. </p>
<p>I do the same with machine learning - applying neural networks and gradient boosted trees without understanding how it transforms my data.</p>
<p>As Richard Feynman puts it: <a href="http://www.haveabit.com/feynman/2" target="_blank" rel="external">“There is a difference between knowing the name of something and knowing something”</a>. This was also featured in the chapter <em>O Americano, Outra Vez</em> of his book <a href="http://www.goodreads.com/book/show/5544.Surely_You_re_Joking_Mr_Feynman_" target="_blank" rel="external">Surely You’re Joking, Mr. Feynman!: Adventures of a Curious Character</a> (I highly recommend reading it!).</p>
<p>My aim for this year is to read more on my new a kindle paperwhite (which I named R2-D2) and understand more about the world! I want to do more scientific Python, computer vision, GPU programming, web apps, blog more and get out more often.</p>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="2014_Review">2014 Review</h2><p>Travelled to 10 different countries in Europe with Seb as the rider and myself as the pillion on his]]>
    </summary>
    
      <category term="stuff" scheme="alyssaq.github.io/categories/stuff/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Understanding Hough Transform With Python]]></title>
    <link href="alyssaq.github.io/2014/understanding-hough-transform/"/>
    <id>alyssaq.github.io/2014/understanding-hough-transform/</id>
    <published>2014-12-14T10:18:00.000Z</published>
    <updated>2015-10-18T08:45:38.000Z</updated>
    <content type="html"><![CDATA[<p>The Hough transform <a href="http://www.ai.sri.com/pubs/files/tn036-duda71.pdf" target="_blank" rel="external">(Duda and Hart, 1972)</a>, which started out as a technique to detect lines in image, has been generalised and extended to detect curves in 2D and 3D.</p>
<p>Here, we understand how an image is transformed into the hough space for line detection and implement it in Python.</p>
<h2 id="How_it_works_-_gradient-intercept_parameter_space">How it works - gradient-intercept parameter space</h2><p>A line in Cartesian form has the equation:<br><img src="https://alyssaq.github.io/blog/images/hough-cartesian_equation.png" style="float:right"></p>
<pre><code>y = mx + b

<span class="keyword">where</span>:    
m = gradient <span class="keyword">or</span> slope <span class="keyword">of</span> <span class="keyword">the</span> line (rise/<span class="command">run</span>)   
b = y-intercept
</code></pre><p>Given a set of edge points or a binary image indicating edges, we want to find as many lines that connect these points in image space.</p>
<p>Say we have 2 edge points ($x_1, y_1$) and ($x_2, y_2$). For each edge point at various gradient values ($m$=-0.5, 1.0, 1.5, etc), we calculate the corresponding $b$ values. The image below shows the various lines through an edge point in image space and the plot of these lines in parameter space. Points which are collinear in the cartesian image space will intersect at a point in $m$-$b$ parameter space.</p>
<p><img src="https://alyssaq.github.io/blog/images/hough-mb_parameter_space.png" alt="mb_space"></p>
<p><strong>All points on a line in image space intersect at a common point in parameter space. This common point ($m$, $b$) represents the line in image space.</strong></p>
<p>Unfortunately, the slope, $m$, is undefined when the line is vertical (division by 0!).<br>To overcome this, we use another parameter space, the hough space.</p>
<h2 id="How_it_works_-_angle-distance_parameter_space">How it works - angle-distance parameter space</h2><p>A line in Polar coordinate system has the equation:</p>
<pre><code>ρ = x <span class="built_in">cos</span> θ + y <span class="built_in">sin</span> θ

where:
ρ (rho) = distance <span class="built_in">from</span> origin <span class="built_in">to</span> <span class="operator">the</span> <span class="built_in">line</span>. [-max_dist <span class="built_in">to</span> max_dist]. 
          max_dist is <span class="operator">the</span> diagonal <span class="built_in">length</span> <span class="operator">of</span> <span class="operator">the</span> image.  
θ = angle <span class="built_in">from</span> origin <span class="built_in">to</span> <span class="operator">the</span> <span class="built_in">line</span>. [-<span class="number">90</span>° <span class="built_in">to</span> <span class="number">90</span>°]
</code></pre><p>If you’re interested in how $\rho$ is derived, I’ve laid out the maths at the bottom <a href="#rho">extras section: deriving rho</a>.</p>
<p>To explain the hough transform, I’ll use a simple example. I’ve created an input binary image of size 30 x 30 pixels with points at (5, 25) and (20, 10) shown below. The image is transformed to the hough space by calculating $\rho$ with a point at each angle from $-90^\circ$ to $90^\circ$ (negative angles are anti-clockwise starting horizontally from the origin and positive angles are clockwise).  The points in hough space make a sinusoidal curve. </p>
<p><img src="https://alyssaq.github.io/blog/images/hough-2point_transform.png" style="float:left"></p>
<p>The value of $\rho$ at various angles for the 2 edge points:</p>
<table>
<thead>
<tr>
<th>point</th>
<th style="text-align:center">$-90^\circ$</th>
<th style="text-align:center">$-45^\circ$</th>
<th style="text-align:center">$0^\circ$</th>
<th style="text-align:center">$45^\circ$</th>
<th style="text-align:center">$90^\circ$</th>
</tr>
</thead>
<tbody>
<tr>
<td>(5, 25)</td>
<td style="text-align:center">-25</td>
<td style="text-align:center">-14</td>
<td style="text-align:center">5</td>
<td style="text-align:center">21</td>
<td style="text-align:center">25</td>
</tr>
<tr>
<td>(20, 10)</td>
<td style="text-align:center">-10</td>
<td style="text-align:center">7</td>
<td style="text-align:center">20</td>
<td style="text-align:center">21</td>
<td style="text-align:center">10</td>
</tr>
</tbody>
</table>
<p><img src="https://alyssaq.github.io/blog/images/hough-final_transformed.png" style="float:right"><br>We see that the curves in hough space intersect at $45^\circ$ with $\rho=21$.<br>Curves generated by collinear points in the image space intersect in peaks $(\rho, \theta)$ in the Hough transform space. The more curves intersect at a point, the more “votes” a line in image space will receive. We’ll see this in the next implementation section.</p>
<h2 id="Algorithm_steps">Algorithm steps</h2><ol>
<li><strong>Corner or edge detection</strong>. (E.g. using <a href="http://scikit-image.org/docs/dev/auto_examples/plot_canny.html" target="_blank" rel="external">canny</a>, <a href="http://scikit-image.org/docs/dev/api/skimage.filter.html?highlight=sobel#sobel" target="_blank" rel="external">sobel</a>, <a href="http://scikit-image.org/docs/dev/api/skimage.filter.html?highlight=sobel#threshold-adaptive" target="_blank" rel="external">adaptive thresholding</a>). The resultant binary/grey image will have 0s indicating non-edges and 1s or above indicating edges. This is our input image.</li>
<li><strong>Rho range and Theta range creation</strong>. $\rho$ ranges from -max_dist to max_dist where max_dist is the diagonal length of the input image. $\theta$ ranges from $-90^\circ$ to $90^\circ$. You can have more or less bins in the ranges to tradeoff accuracy, space and speed. E.g. Every third angle in $-90^\circ$ to $90^\circ$ to reduce from 180 to 60 values.</li>
<li><strong>Hough accumulator</strong> of $\theta$ vs $\rho$. It is a 2D array with the number of rows equal to the number of $\rho$ values and the number of columns equal to the number of $\theta$ values.</li>
<li><strong>Voting in the accumulator</strong>. For each edge point and for each $\theta$ value, find the nearest $\rho$ value and increment that index in the accumulator. Each element tells how many points/pixels contributed “votes” for potential line candidates with parameters $(\rho, \theta)$.</li>
<li><strong>Peak finding</strong>. Local maxima in the accumulator indicates the parameters of the most prominent lines in the input image. Peaks can be found most easily by applying a threshold or a relative threshold (values equal to or greater than some fixed percentage of the global maximum value).</li>
</ol>
<h2 id="Code_Time">Code Time</h2><p>Full code on <a href="https://github.com/alyssaq/hough_transform" target="_blank" rel="external"><i class="fa fa-github-alt"></i> github</a></p>
<pre class="line-numbers"><code class="language-python">
import numpy as np

def hough_line(img):
  # Rho and Theta ranges
  thetas = np.deg2rad(np.arange(-90.0, 90.0))
  width, height = img.shape
  diag_len = np.ceil(np.sqrt(width * width + height * height))   # max_dist
  rhos = np.linspace(-diag_len, diag_len, diag_len * 2.0)

  # Cache some resuable values
  cos_t = np.cos(thetas)
  sin_t = np.sin(thetas)
  num_thetas = len(thetas)

  # Hough accumulator array of theta vs rho
  accumulator = np.zeros((2 * diag_len, num_thetas), dtype=np.uint64)
  y_idxs, x_idxs = np.nonzero(img)  # (row, col) indexes to edges

  # Vote in the hough accumulator
  for i in range(len(x_idxs)):
    x = x_idxs[i]
    y = y_idxs[i]

    for t_idx in range(num_thetas):
      # Calculate rho. diag_len is added for a positive index
      rho = round(x * cos_t[t_idx] + y * sin_t[t_idx]) + diag_len
      accumulator[rho, t_idx] += 1

  return accumulator, thetas, rhos 
</code></pre>


<p>Usage:</p>
<pre class="line-numbers"><code class="language-python">
# Create binary image and call hough_line
image = np.zeros((50,50))
image[10:40, 10:40] = np.eye(30)
accumulator, thetas, rhos = hough_line(image)

# Easiest peak finding based on max votes
idx = np.argmax(accumulator)
rho = rhos[idx / accumulator.shape[1]]
theta = thetas[idx % accumulator.shape[1]]
print "rho={0:.2f}, theta={1:.0f}".format(rho, np.rad2deg(theta))
</code></pre>

<pre><code>rho=<span class="number">0.50</span>, theta=-<span class="number">45</span>
</code></pre><p>Hough transform (and the faster probabilistic version) is available in <a href="http://docs.opencv.org/doc/tutorials/imgproc/imgtrans/hough_lines/hough_lines.html" target="_blank" rel="external">openCV</a> and <a href="http://scikit-image.org/docs/dev/auto_examples/plot_line_hough_transform.html" target="_blank" rel="external">scikit-image</a>.</p>
<h2 id="Extensions">Extensions</h2><p>Hough transform can be extended to detect circles of the equation<br>$r^2 = (x − a)^2 + (y − b)^2$ in the parameter space, $\rho = (a, b, r)$.<br>Furthermore, it can be generalized to detect arbitrary shapes <a href="http://comp-eng.binus.ac.id/files/2012/04/D.H.-Ballard-Generalizing-the-Hough-Transform-to-Detect-Arbitrary-Shapes1.pdf" target="_blank" rel="external">(D. H. Ballard, 1981)</a>.</p>
<p>Another approach is the Progressive Probabilistic Hough Transform <a href="http://cmp.felk.cvut.cz/~matas/papers/matas-bmvc98.pdf" target="_blank" rel="external">(Galamhos et al, 1999)</a>. The algorithm uses  random subsets of voting points in the accumulator and checks for the longest segment of pixels with minimum gaps. Line segments that exceed a minimum length threshold are added to the list. This returns the beginning and end point of each line segment in the image. It has 3 thresholds: a minimum number of votes in the Hough accumulator, a maximum line gap for merging and a minimum line length. </p>
<p>##Extras</p>
<h3 id="Deriving_rho:_ρ_=_x_cos_θ_+_y_sin_θ"><a name="rho"></a> Deriving rho: ρ = x cos θ + y sin θ</h3><p><img src="https://alyssaq.github.io/blog/images/hough_deriving-rho.png" style="float:left;"> </p>
<p>With basic trigonometry, we know that for right-angled triangles,<br>$sin \theta = {opposite\over hypotenuse}$ and $cos \theta = {adjacent \over hypotenuse}$.  </p>
<p>We want to convert the cartesian form $y = mx + b$ with parameters $(m, b)$ to polar form with parameters $(\rho, \theta)$. </p>
<p>The line from the origin with distance $\rho$ has a gradient of ${sin \theta \over cos \theta}$. The line of interest, which is perpendicular to it, will have a negative reciprocal gradient value of ${-cos \theta \over sin \theta}$. For $b$, the y-intercept of the line of interest, $sin \theta = {\rho \over b}$.</p>
<p>With $m = {-cos \theta \over sin \theta}$ and $b = {\rho \over sin \theta}$, we get   $\rho = x \ cos \theta + y \ sin \theta$.</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>The Hough transform <a href="http://www.ai.sri.com/pubs/files/tn036-duda71.pdf" target="_blank" rel="external">(Duda and Hart, 1972)</a>,]]>
    </summary>
    
      <category term="computer vision" scheme="alyssaq.github.io/tags/computer-vision/"/>
    
      <category term="python" scheme="alyssaq.github.io/tags/python/"/>
    
      <category term="data science" scheme="alyssaq.github.io/categories/data-science/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Installing OpenCV on Mac OSX With Homebrew]]></title>
    <link href="alyssaq.github.io/2014/installing-opencv-on-mac-osx-with-homebrew/"/>
    <id>alyssaq.github.io/2014/installing-opencv-on-mac-osx-with-homebrew/</id>
    <published>2014-08-18T08:24:00.000Z</published>
    <updated>2015-10-18T08:45:08.000Z</updated>
    <content type="html"><![CDATA[<ol>
<li>Install the package manager <a href="http://brew.sh/" target="_blank" rel="external">Homebrew</a>. It beats MacPorts any day.</li>
<li><p>Go ahead and install <a href="http://opencv.org/" target="_blank" rel="external">OpenCV</a>:</p>
<pre><code>$ <span class="keyword">brew </span>install opencv
</code></pre></li>
<li><p>If all is well, it should be available at:</p>
<pre><code>/usr/local/Cellar/opencv/<span class="number">2.4</span><span class="number">.9</span>
</code></pre></li>
<li><p>Create a symlink to the compiled OpenCV files. If you don’t mind setting up your <code>PYTHONPATH</code> and messing up python2 and python3 support, you may use <code>brew link opencv</code>. Otherwise, I recommend doing the manual symlink to your Python 2.7 site-packages.</p>
<pre><code><span class="variable">$ </span>sudo ln -s /usr/local/<span class="constant">Cellar</span>/opencv/<span class="number">2.4</span>.<span class="number">9</span>/<span class="class"><span class="keyword">lib</span>/<span class="title">python2</span>.7/<span class="title">site</span>-<span class="title">packages</span>/<span class="title">cv</span>.<span class="title">py</span> /<span class="title">Library</span>/<span class="title">Python</span>/2.7/<span class="title">site</span>-<span class="title">packages</span>/<span class="title">cv</span>.<span class="title">py</span></span>
<span class="variable">$ </span>sudo ln -s /usr/local/<span class="constant">Cellar</span>/opencv/<span class="number">2.4</span>.<span class="number">9</span>/<span class="class"><span class="keyword">lib</span>/<span class="title">python2</span>.7/<span class="title">site</span>-<span class="title">packages</span>/<span class="title">cv2</span>.<span class="title">so</span> /<span class="title">Library</span>/<span class="title">Python</span>/2.7/<span class="title">site</span>-<span class="title">packages</span>/<span class="title">cv2</span>.<span class="title">so</span> </span>
</code></pre></li>
<li><p>Check that it works!</p>
<pre><code>$ ipython
Python <span class="number">2.7</span>.<span class="number">9</span>
[GCC <span class="number">4.2</span>.<span class="number">1</span> (Apple Inc. build <span class="number">5666</span>) (dot <span class="number">3</span>)] on darwin
Type <span class="string">"help"</span>, <span class="string">"copyright"</span>, <span class="string">"credits"</span> or <span class="string">"license"</span> ...

In [<span class="number">1</span>]: import cv2
In [<span class="number">2</span>]: <span class="tag">img</span> = cv2.<span class="function"><span class="title">imread</span><span class="params">(<span class="string">'path-to-image/helloworld.jpg'</span>)</span></span>
In [<span class="number">3</span>]: cv2.<span class="function"><span class="title">imshow</span><span class="params">(<span class="string">'Test image'</span>, img)</span></span>
</code></pre></li>
</ol>
<p>To check locations of site-packages folders:</p>
<pre><code><span class="name">In</span> [<span class="number">4</span>]: <span class="atom">import</span> <span class="atom">site</span>; <span class="atom">site</span>.<span class="atom">getsitepackages</span>()
<span class="name">Out</span>[<span class="number">4</span>]:
[<span class="string">'/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages'</span>,
  <span class="string">'/Library/Frameworks/Python.framework/Versions/2.7/lib/site-python'</span>,
  <span class="string">'/Library/Python/2.7/site-packages'</span>]
</code></pre>]]></content>
    <summary type="html">
    <![CDATA[<ol>
<li>Install the package manager <a href="http://brew.sh/" target="_blank" rel="external">Homebrew</a>. It beats MacPorts any day.</li>
]]>
    </summary>
    
      <category term="mac" scheme="alyssaq.github.io/tags/mac/"/>
    
      <category term="opencv" scheme="alyssaq.github.io/tags/opencv/"/>
    
      <category term="tech" scheme="alyssaq.github.io/categories/tech/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[How to Run SlimerJS and PhantomJS With CircleCI]]></title>
    <link href="alyssaq.github.io/2014/how-to-run-slimerjs-and-phantomjs-with-circleci/"/>
    <id>alyssaq.github.io/2014/how-to-run-slimerjs-and-phantomjs-with-circleci/</id>
    <published>2014-05-25T09:56:00.000Z</published>
    <updated>2015-10-18T08:44:57.000Z</updated>
    <content type="html"><![CDATA[<h2 id="Goal">Goal</h2><p>Automatically run user-driven tests (BDD) with <a href="http://slimerjs.org/" target="_blank" rel="external">SlimerJS</a> for testing on Gecko (firefox) and <a href="http://phantomjs.org/" target="_blank" rel="external">PhantomJS</a> for WebKit (chrome/safari) on the continuous integration platform, <a href="https://circleci.com/" target="_blank" rel="external">CircleCI</a>.</p>
<h3 id="Auto_testing_on_CircleCI">Auto testing on CircleCI</h3><p><a href="https://circleci.com/docs/environment#browsers" target="_blank" rel="external">CircleCI’s test environment</a> is preinstalled with CasperJS and PhantomJS but does not have SlimerJS installed. To get started, all you need is a <a href="https://circleci.com/docs/configuration" target="_blank" rel="external"><code>circle.yml</code></a> file in your repository, activate it in your CircleCI account and it’ll automatically run <code>npm test</code> if you’re using NodeJS. I also use it for my Python applications.</p>
<p>Running unit tests and just PhantomJS tests is simple and documented on their site but getting SlimerJS working took a little more Googling and trial-and-error. Heres how I set it up.</p>
<h3 id="Custom_commands_to_use_SlimerJS_on_CircleCI">Custom commands to use SlimerJS on CircleCI</h3><p>Firstly, in the <code>circle.yml</code> file, specify custom commands  to download the SlimerJS standalone installer (currently at 0.9.1). Extract the files and move them to a known directory. Moving the files to a known directly is the key! </p>
<pre><code>test:
  pre:
    - curl -k -L -o slimerjs<span class="class">.tar</span><span class="class">.bz2</span> http:<span class="comment">//download.slimerjs.org/v0.9/0.9.1/slimerjs-0.9.1-linux-x86_64.tar.bz2</span>
    - tar -jxf slimerjs<span class="class">.tar</span><span class="class">.bz2</span>
    - mv slimerjs-<span class="number">0.9</span>.<span class="number">1</span> <span class="variable">$HOME</span>/slimerjs
</code></pre><p>I do this in the <code>test:pre</code> section to have SlimerJS available before running the tests.</p>
<p>Next, add the required environment variables to CircleCI.</p>
<pre><code>machine:
  environment:
    SLIMERJSLAUNCHER: $(which firefox)
    PATH: <span class="variable">$PATH</span>:<span class="variable">$HOME</span>/slimerjs
</code></pre><p>Just ensure that the <code>PATH</code> environment contains the same directory as where you extracted the SlimerJS files.</p>
<p>Heres my full <code>circle.yml</code> file with auto-deployment to Heroku and a web hook to my circleCI 2 slack herokuapp with names removed.</p>
<pre><code>machine:
      environment:
        SLIMERJSLAUNCHER: $(which firefox)
        PATH: <span class="variable">$PATH</span>:<span class="variable">$HOME</span>/slimerjs
test:
  pre:
    - bower install
    - curl -k -L -o slimerjs.tar.bz2 http://download.slimerjs.org/v<span class="number">0</span>.<span class="number">9</span>/<span class="number">0</span>.<span class="number">9.1</span>/slimerjs-<span class="number">0</span>.<span class="number">9.1</span>-linux-x86_64.tar.bz2
    - tar -jxf slimerjs.tar.bz2
    - mv slimerjs-<span class="number">0</span>.<span class="number">9.1</span> <span class="variable">$HOME</span>/slimerjs
deployment:
  production:
    branch: master
    heroku:
      appname: my-production-herokuapp
  staging:
    branch: develop
    heroku:
      appname: my-staging-herokuapp
notify:
  webhooks:
    - url: https://my-circleci2slack.herokuapp.com/
</code></pre><p>If all is good, you should see green lights in all the rows in circleCI:<br><img src="https://alyssaq.github.io/blog/images/SlimerJS-circleCI.png" alt="image"></p>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="Goal">Goal</h2><p>Automatically run user-driven tests (BDD) with <a href="http://slimerjs.org/" target="_blank" rel="external">Slime]]>
    </summary>
    
      <category term="javascript" scheme="alyssaq.github.io/tags/javascript/"/>
    
      <category term="tech" scheme="alyssaq.github.io/categories/tech/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Window Tiling in OS X]]></title>
    <link href="alyssaq.github.io/2014/window-titling-in-os-x/"/>
    <id>alyssaq.github.io/2014/window-titling-in-os-x/</id>
    <published>2014-05-13T10:16:00.000Z</published>
    <updated>2015-10-18T08:44:52.000Z</updated>
    <content type="html"><![CDATA[<p>Discovered window tiling for my Mac and absolutely love it!</p>
<p>Its open-source, light-weight and does what I need:<br><a href="http://spectacleapp.com/" target="_blank" rel="external">spectacleapp</a></p>
<p>Shortcuts to snap any application to left-half, right-half, quarter, thirds.<br>Its awesome!</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>Discovered window tiling for my Mac and absolutely love it!</p>
<p>Its open-source, light-weight and does what I need:<br><a href="http:/]]>
    </summary>
    
      <category term="mac" scheme="alyssaq.github.io/tags/mac/"/>
    
      <category term="stuff" scheme="alyssaq.github.io/categories/stuff/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[How Do I Return a HTTP Response to Caller and Continue Processing]]></title>
    <link href="alyssaq.github.io/2014/how-do-I-return-a-http-response-to-caller-and-continue-processing/"/>
    <id>alyssaq.github.io/2014/how-do-I-return-a-http-response-to-caller-and-continue-processing/</id>
    <published>2014-04-02T05:33:00.000Z</published>
    <updated>2015-10-18T09:04:06.000Z</updated>
    <content type="html"><![CDATA[<h2 id="Scenario">Scenario</h2><p>I have an analysis service that is invoked by posting data via its API.<br>Since the processing could be long-running, it is best to return a response to the caller and continue with the data.  </p>
<h2 id="Goal">Goal</h2><p>Return a 200 HTTP response to the caller upon receiving valid data.<br>After returning the response, continue processing the data and post the results to another endpoint.</p>
<h2 id="Potential_solutions">Potential solutions</h2><ul>
<li>Multithreading</li>
<li>Multiprocessing</li>
<li>Message Queues such as <a href="http://www.celeryproject.org/" target="_blank" rel="external">celery</a>, <a href="http://python-rq.org/" target="_blank" rel="external">python-rq</a> or <a href="http://www.iron.io/mq" target="_blank" rel="external">ironMQ</a></li>
</ul>
<h2 id="Python_multithreading">Python multithreading</h2><p>Between <a href="#multithreading_multiprocessing">multithreading and multiprocessing</a>, using threads was sufficient for my requirements. I ended up using Python’s <a href="https://docs.python.org/2/library/threading.html" target="_blank" rel="external">threading</a> library.</p>
<p>Below is the <a href="https://gist.github.com/alyssaq/9928442" target="_blank" rel="external">code gist</a> to handle POST requests and continue processing with threads.<br>Tested with <code>python 2.7</code> and <code>python 3.3</code> </p>
<pre><code class="language-python">
#!/usr/bin/env python
# -*- coding: utf-8 -*-

""" Sample multithreading with bottle.py
Requirements: requests, bottle

To run: 
$ python app.py

To post data, open another command shell and type:
$ curl -X POST -H "Content-Type: application/json" -d '{"data":"test"}' http://127.0.0.1:8080/process -D-

"""
import bottle
import json
import requests
from threading import Thread

POSTBACK_URL = 'http://127.0.0.1:8080/postprocessed'

@bottle.post('/postprocessed')
def postprocessed_handle():
  print('Received data at postprocessed')
  return bottle.HTTPResponse(status=200, body="Complete postprocessed")

def process_data(data):
  # do processing...
  result = json.dumps(data)

  print('Finished processing')
  requests.post(POSTBACK_URL, data=result, 
    headers={'Content-Type':'application/json'})

@bottle.post('/process')
def process_handle():
  data = bottle.request.json.get('data', False)
  print('Received data at process: ' + data)

  if not data:
    return bottle.HTTPResponse(status=400, body="Missing data")

  #Spawn thread to process the data
  t = Thread(target=process_data, args=(data, ))
  t.start()

  #Immediately return a 200 response to the caller
  return bottle.HTTPResponse(status=200, body="Complete process")

if __name__ == '__main__':
  bottle.run()
</code></pre>

<h2 id="Terminologies">Terminologies</h2><h3 id="multithreading_vs_multiprocessing"><a name="multithreading_multiprocessing"></a> multithreading vs multiprocessing</h3><ul>
<li>A thread is the smallest sequence of instructions within a process</li>
<li>A process is an instance of a computer program that is being executed.</li>
</ul>
<table>
<thead>
<tr>
<th>Threads</th>
<th>Processes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Share address space</td>
<td>Separate address space</td>
</tr>
<tr>
<td>Share process state, memory <br>and other resources</td>
<td>Carries more state information</td>
</tr>
<tr>
<td>thread lifetime, context switching and <br>synchronisation costs are lower</td>
<td>slower context switching between <br>processes than threads </td>
</tr>
<tr>
<td>Exist as subsets of a process</td>
<td>Typically independent. Insulated <br>from each other by the OS</td>
</tr>
<tr>
<td>An error in a thread can kill all the <br> other threads in the same process</td>
<td>An error in a process <br>may not affect another process</td>
</tr>
</tbody>
</table>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="Scenario">Scenario</h2><p>I have an analysis service that is invoked by posting data via its API.<br>Since the processing could be l]]>
    </summary>
    
      <category term="api" scheme="alyssaq.github.io/tags/api/"/>
    
      <category term="multithreading" scheme="alyssaq.github.io/tags/multithreading/"/>
    
      <category term="python" scheme="alyssaq.github.io/tags/python/"/>
    
      <category term="queue" scheme="alyssaq.github.io/tags/queue/"/>
    
      <category term="tech" scheme="alyssaq.github.io/categories/tech/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Ready Player One - Summary and After-Effects]]></title>
    <link href="alyssaq.github.io/2014/ready-player-one--summary-and-aftereffects/"/>
    <id>alyssaq.github.io/2014/ready-player-one--summary-and-aftereffects/</id>
    <published>2014-03-10T09:46:00.000Z</published>
    <updated>2015-10-18T08:44:27.000Z</updated>
    <content type="html"><![CDATA[<p>You have to read <a href="https://www.goodreads.com/book/show/9969571-ready-player-one" target="_blank" rel="external">Ready Player One (2011)</a> by Ernest Cline!</p>
<p>I have a major soft spot for utopian and dystopian future societies and characters. Throw in immersive virtual reality, artificial intelligence, pervasive computing vision, haptic technologies, Japanese culture and I’m in virtual heaven.<br><a href="http://www.ted.com/talks/ray_kurzweil_on_how_technology_will_transform_us" target="_blank" rel="external">Progress in technology is exponential</a> and we’ll be able to merge with our technology within the next decade. No, no alien invasion.</p>
<h2 id="Welcome_to_Ready_Player_One">Welcome to Ready Player One</h2><p>In the dystopian 2044, a free-to-use virtual universe known as OASIS has become a daily refuge from the ugly real world and school systems are available online. When the creator, Halliday, dies without heirs, he leaves his $240 billion fortune and OASIS control to the finder of his Easter Egg.<br>To win, players have to unravel a series of riddles and video games which have been built around Halliday’s obsession of 80’s pop culture. We follow Wade Watt’s convolutions of his race towards the Egg in this highly entertaining, thrilling and addictive game within a novel.</p>
<p>As someone who often takes refuge from the real world by spending hours coding, reading and watching anime/movies, it wasn’t hard relating to Wade’s introvert nature and enjoying the vivid descriptions of OASIS and the characters involved. </p>
<h2 id="Causatum_of_reading_Ready_Player_One">Causatum of reading Ready Player One</h2><p>It took me a few days to plough though the book, mainly starting before midnight through to the full sunrise. My body clock is upside down but damn was  it worth the read. </p>
<p>Since finishing the book and going through countless reviews, it has given me a list of movies to see and list of books to read. It has also boosted my interest and motivation to get back into machine learning and computer vision.</p>
<p>After creating a mini web app, <a href="https://github.com/alyssaq/face-find-fun" target="_blank" rel="external">face-find-fun</a> to detect, track and draw a party hat on your head with the webcam, I  haven’t done anything CV-related. Any ideas?</p>
<p>I would like to go through the <a href="http://scikit-learn.org/stable/tutorial/" target="_blank" rel="external">scikit-learn</a> tutorials but it looks dry without an application in mind. Perhaps a <em>selfie-detector</em> -<br>Input: a bunch of positive images of yourself and negative images of your friends.<br>Output: Given an image, <em>selfie-detector</em> verifies it its you.</p>
<p>###Movies<br>Here is a list of movies referenced in the book and reviews.<br>(Schoolhouse Rock! is not a movie but it was a rocking educational game with videos that I played as a little girl)</p>
<ul>
<li>Blade Runner (1982) - <a href="http://www.rottentomatoes.com/m/blade_runner/" target="_blank" rel="external">RT 91%</a>, <a href="http://www.imdb.com/title/tt0083658/" target="_blank" rel="external">IMDb 83%</a>. Watched! V. Good!</li>
<li>Brainstorm (1983) - <a href="http://www.rottentomatoes.com/m/1003017-brainstorm/" target="_blank" rel="external">RT 63%</a>, <a href="http://www.imdb.com/title/tt0085271/?ref_=fn_al_tt_2" target="_blank" rel="external">IMDb 65%</a>. Wont watch</li>
<li>Brazil (1985) - <a href="http://www.rottentomatoes.com/m/1003033-brazil/" target="_blank" rel="external">RT 98%</a>, <a href="http://www.imdb.com/title/tt0088846/?ref_=fn_al_tt_1" target="_blank" rel="external">imdb 80%</a>. Will watch</li>
<li>Explorers (1985) - <a href="http://www.rottentomatoes.com/m/explorers/" target="_blank" rel="external">RT 77%</a>, <a href="http://www.imdb.com/title/tt0089114/?ref_=fn_al_tt_1" target="_blank" rel="external">IMDb 66%</a>. Wont watch</li>
<li>Highlander (1986) - <a href="http://www.rottentomatoes.com/m/highlander/" target="_blank" rel="external">RT 67%</a>, <a href="http://www.imdb.com/title/tt0091203/?ref_=fn_al_tt_1" target="_blank" rel="external">IMDb 72%</a>. Might watch</li>
<li>Ladyhawke (1985) - <a href="http://www.rottentomatoes.com/m/ladyhawke/" target="_blank" rel="external">RT 67%</a>, <a href="http://www.imdb.com/title/tt0089457/?ref_=fn_al_tt_1" target="_blank" rel="external">IMDb 69%</a>. Might watch</li>
<li>Monty Python and the Holy Grail (1975) - <a href="http://www.rottentomatoes.com/m/monty_python_and_the_holy_grail/" target="_blank" rel="external">RT 97%</a>, <a href="http://www.imdb.com/title/tt0071853/?ref_=fn_al_tt_1" target="_blank" rel="external">IMDb 84%</a>. Will watch</li>
<li>Risky Business (1983) - <a href="http://www.rottentomatoes.com/m/1017641-risky_business/" target="_blank" rel="external">RT 98%</a>, <a href="http://www.imdb.com/title/tt0086200/?ref_=fn_al_tt_1" target="_blank" rel="external">IMDb 68%</a>. Might watch</li>
<li><a href="http://www.imdb.com/title/tt0069627/" target="_blank" rel="external">Schoolhouse Rock!</a>. Watched! Played! V. Good!</li>
<li>Serenity (2005) - <a href="http://www.rottentomatoes.com/m/serenity/" target="_blank" rel="external">RT 82%</a>, <a href="http://www.imdb.com/title/tt0379786/?ref_=fn_al_tt_1" target="_blank" rel="external">IMDb 81%</a>. Will watch</li>
<li>Short Circuit (1986) - <a href="http://www.rottentomatoes.com/m/1018891-short_circuit/" target="_blank" rel="external">RT 57%</a>, <a href="http://www.imdb.com/title/tt0091949/?ref_=fn_al_tt_1" target="_blank" rel="external">IMDb 65%</a>. Wont watch</li>
<li>The Breakfast Club (1985) - <a href="http://www.rottentomatoes.com/m/breakfast_club/" target="_blank" rel="external">RT 91%</a>, <a href="http://www.imdb.com/title/tt0088847/?ref_=fn_al_tt_1" target="_blank" rel="external">IMDb 71%</a>. Might watch</li>
<li>The Dark Crystal (1982) - <a href="http://www.rottentomatoes.com/m/dark_crystal/" target="_blank" rel="external">RT 71%</a>, <a href="http://www.imdb.com/title/tt0083791/?ref_=fn_al_tt_1" target="_blank" rel="external">IMDb 72%</a>. Might watch</li>
<li>Silence of the Lambs (1991) - <a href="http://www.rottentomatoes.com/m/silence_of_the_lambs/" target="_blank" rel="external">RT 94%</a>, <a href="http://www.imdb.com/title/tt0102926/" target="_blank" rel="external">IMDb 86%</a>. Will watch</li>
<li>THX 1138 (1971) - <a href="http://www.rottentomatoes.com/m/thx_1138/" target="_blank" rel="external">RT 86%</a>, <a href="http://www.imdb.com/title/tt0066434/?ref_=fn_al_tt_1" target="_blank" rel="external">IMDb 68%</a>. Will watch</li>
<li>Tron (1982) - <a href="http://www.rottentomatoes.com/m/tron/" target="_blank" rel="external">RT 71%</a>, <a href="http://www.imdb.com/title/tt0084827/?ref_=fn_al_tt_1" target="_blank" rel="external">IMDb 68%</a>. Watched. V. Good!</li>
<li>Vision Quest (1985) - <a href="http://www.rottentomatoes.com/m/vision_quest_1985/" target="_blank" rel="external">RT 58%</a>, <a href="http://www.imdb.com/title/tt0090270/?ref_=fn_al_tt_1" target="_blank" rel="external">IMDb 64%</a>. Might watch</li>
<li>WarGames (1983) - <a href="http://www.rottentomatoes.com/m/wargames/" target="_blank" rel="external">RT 92%</a>, <a href="http://www.imdb.com/title/tt0086567/?ref_=fn_al_tt_1" target="_blank" rel="external">IMDb 71%</a>. Will watch</li>
<li>Weird Science (1985) - <a href="http://www.rottentomatoes.com/m/1023316-weird_science/" target="_blank" rel="external">RT 56%</a>, <a href="http://www.imdb.com/title/tt0090305/?ref_=fn_al_tt_1" target="_blank" rel="external">IMDb 66%</a>. Wont watch</li>
</ul>
<p>###Books</p>
<ul>
<li><a href="http://www.goodreads.com/book/show/40445.Altered_Carbon" target="_blank" rel="external">Altered Carbon (2002) by Richard K. Morgan</a></li>
<li><a href="http://www.goodreads.com/book/show/234225.Dune" target="_blank" rel="external">Dune (1965) by Frank Herbert</a></li>
<li><a href="http://www.goodreads.com/book/show/13.The_Ultimate_Hitchhiker_s_Guide_to_the_Galaxy" target="_blank" rel="external">Hitchhiker’s Guide to the Galaxy (1979-2009) by Douglas Adams, Neil Gaiman</a></li>
<li><a href="http://www.goodreads.com/book/show/22328.Neuromancer" target="_blank" rel="external">Neuromancer (1984) by William Gibson</a></li>
<li><a href="http://www.goodreads.com/book/show/830.Snow_Crash" target="_blank" rel="external">Snow Crash (1992) by Neal Stephenson</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>You have to read <a href="https://www.goodreads.com/book/show/9969571-ready-player-one" target="_blank" rel="external">Ready Player One (]]>
    </summary>
    
      <category term="book" scheme="alyssaq.github.io/tags/book/"/>
    
      <category term="ready_player_one" scheme="alyssaq.github.io/tags/ready-player-one/"/>
    
      <category term="stuff" scheme="alyssaq.github.io/categories/stuff/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Deploy a Python Web App With 3rd-Party Packages to Heroku]]></title>
    <link href="alyssaq.github.io/2014/deploy-a-python-web-app-with-3rdparty-packages-to-heroku/"/>
    <id>alyssaq.github.io/2014/deploy-a-python-web-app-with-3rdparty-packages-to-heroku/</id>
    <published>2014-02-18T16:34:00.000Z</published>
    <updated>2015-10-18T08:44:16.000Z</updated>
    <content type="html"><![CDATA[<h2 id="Goal">Goal</h2><p>To deploy a Python web app with various mathematical, scientific, text-processing packages to a cloud hosting <a href="http://en.wikipedia.org/wiki/Platform_as_a_service" target="_blank" rel="external">platform-as-a-service</a>.</p>
<p>My required 3rd-party Python packages/modules:</p>
<ul>
<li><a href="http://numpy.org" target="_blank" rel="external">Numpy</a> (fundamental package for scientific computing with numbers)</li>
<li><a href="http://scipy.org" target="_blank" rel="external">Scipy</a> (scientific computing tools)</li>
<li><a href="http://pandas.pydata.org" target="_blank" rel="external">Pandas</a> (high-performance, easy-to-use data structures for data pre-processing and analytics)</li>
<li><a href="http://scikit-learn.org" target="_blank" rel="external">Scikit-learn</a> (machine learning, data mining, data analysis) </li>
<li><a href="textblob.readthedocs.org">Textblob</a> (simplified text-processing version of <a href="http://nltk.org" target="_blank" rel="external">nltk</a>)</li>
</ul>
<h3 id="What_I_tried_and_failed">What I tried and failed</h3><p>I spent a few hours attempting to create a boilerplate web application with the required packages to be deployed on Google App Engine. Creating a restful API for GAE was easy (<a href="https://github.com/alyssaq/flask-restful-api-appengine" target="_blank" rel="external">heres mine on Github</a> using Flask). However, adding the scientific packages I needed was Hell. </p>
<p>In summary, GAE does <a href="https://developers.google.com/appengine/kb/general#libraries" target="_blank" rel="external">NOT support a lot of C-based modules</a>. So, say goodbye to a handful of Python scientific packages which depend on compiling various C-based libraries.<br>While GAE does provide numpy, if you want pandas at some imaginary point in the future, you’ll have to <a href="https://code.google.com/p/googleappengine/issues/detail?id=8620" target="_blank" rel="external">vote on their thread</a>. </p>
<p>Next up, PiCloud. Oh, they joined Dropbox and no longer allow sign-ups. </p>
<p>No, I do not want to bother with AWS. No, I do not want to merely run analytics up in the cloud with wakari or pythonanywhere.</p>
<h2 id="Deploy_scientific_Python_with_Heroku_buildpack">Deploy scientific Python with Heroku buildpack</h2><p>Building numpy, scipy, pandas, etc over and over again with each deployment gets old VERY quick.<br><em>Solution:</em> Use a <a href="https://devcenter.heroku.com/articles/buildpacks" target="_blank" rel="external">buildpack</a> to prepare your dyno before your app executes. The custom buildpacks listed below uses the binary distributions of the required packages so this means not having to build numpy with each push to Heroku (joy!). </p>
<p>Useful Buildpacks:</p>
<ul>
<li><a href="https://github.com/heroku/heroku-buildpack-python" target="_blank" rel="external">Heroku’s python buildpack</a> - for simple python web apps</li>
<li><a href="https://github.com/dbrgn/heroku-buildpack-python-sklearn" target="_blank" rel="external">Above buildpack + base scientific packages</a> - for python web apps with numpy, scipy and/or scikit-learn (only Python 2.7.4)</li>
<li><a href="https://github.com/alyssaq/heroku-buildpack-python-sklearn" target="_blank" rel="external">Above buildpack + textblob with core nltk corpora</a> - this is my fork of the above buildpack with a script to download and cache core nltk corpora for textblob. </li>
</ul>
<h3 id="How_to_deploy_with_a_Heroku_buildpack">How to deploy with a Heroku buildpack</h3><p>1) Create a simple Python web app that imports some scientific packages. As an example, Im using <a href="https://github.com/alyssaq/bottle-heroku-skeleton" target="_blank" rel="external">my bottle-skeleton app</a></p>
<p>2) Clone the repo and add to git:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ git <span class="built_in">clone</span> git@github.com:alyssaq/bottle-heroku-skeleton.git</span><br><span class="line">$ git init</span><br><span class="line">$ git add .</span><br><span class="line">$ git commit -m <span class="string">"init"</span></span><br></pre></td></tr></table></figure>
<p>3) Add any additional dependencies in <code>requirements.txt</code> (the skeleton app already includes numpy, textblob and pandas)</p>
<p>4) Login to heroku, set the custom buildpack and deploy!</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ heroku login</span><br><span class="line">$ heroku config:<span class="built_in">set</span> BUILDPACK_URL=https://github.com/alyssaq/heroku-buildpack-python-sklearn</span><br><span class="line">$ git push heroku master</span><br></pre></td></tr></table></figure>
<p>5) Open your browser and ensure that the home page loads with the <code>Hi</code> text. If it does, its all good to go.</p>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="Goal">Goal</h2><p>To deploy a Python web app with various mathematical, scientific, text-processing packages to a cloud hosting <a h]]>
    </summary>
    
      <category term="automation" scheme="alyssaq.github.io/tags/automation/"/>
    
      <category term="heroku" scheme="alyssaq.github.io/tags/heroku/"/>
    
      <category term="numpy" scheme="alyssaq.github.io/tags/numpy/"/>
    
      <category term="pandas" scheme="alyssaq.github.io/tags/pandas/"/>
    
      <category term="python" scheme="alyssaq.github.io/tags/python/"/>
    
      <category term="tech" scheme="alyssaq.github.io/categories/tech/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[View Math Equations in Markdown With MathJax]]></title>
    <link href="alyssaq.github.io/2014/view-math-equations-in-markdown-with-mathjax/"/>
    <id>alyssaq.github.io/2014/view-math-equations-in-markdown-with-mathjax/</id>
    <published>2014-02-02T11:00:00.000Z</published>
    <updated>2015-10-18T08:43:57.000Z</updated>
    <content type="html"><![CDATA[<p><a href="http://docs.mathjax.org/en/latest/mathjax.html" target="_blank" rel="external">MaxJax</a> is an open-source JavaScript display engine for LaTeX, MathML, and AsciiMath notation that works in all modern browsers. </p>
<p>1) Add the MathJax script from cdn into your HTML. I use the TeX syntax but you can also use mathML by including it in the config parameter. (For scriptogr.am, its under tools &gt; HTML editor).</p>
<pre><code><span class="tag">&lt;<span class="title">script</span> <span class="attribute">type</span>=<span class="value">"text/javascript"</span> <span class="attribute">src</span>=<span class="value">"http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"</span>&gt;</span><span class="undefined"></span><span class="tag">&lt;/<span class="title">script</span>&gt;</span>
</code></pre><p>2) Change the default inline math delimiters of <code>\(...\)</code> as the brackets mean something else in markdown.</p>
<pre><code>&lt;<span class="atom">script</span> <span class="atom">type</span>=<span class="string">"text/x-mathjax-config"</span>&gt;
  <span class="name">MathJax</span>.<span class="name">Hub</span>.<span class="name">Config</span>({
    <span class="atom">extensions</span>: [<span class="string">"tex2jax.js"</span>],
    <span class="atom">jax</span>: [<span class="string">"input/TeX"</span>, <span class="string">"output/HTML-CSS"</span>],
    <span class="atom">tex2jax</span>: {
      <span class="atom">inlineMath</span>: [ [<span class="string">'$'</span>,<span class="string">'$'</span>]],
      <span class="atom">displayMath</span>: [ [<span class="string">'$$'</span>,<span class="string">'$$'</span>]],
      <span class="atom">processEscapes</span>: <span class="atom">true</span>
    },
    <span class="string">"HTML-CSS"</span>: { <span class="atom">availableFonts</span>: [<span class="string">"TeX"</span>] }
  });
&lt;/<span class="atom">script</span>&gt;
</code></pre><p>So, <code>$$ y = mx + b $$</code> appears on a new line:<br>$$ y = mx + b $$</p>
<p>and <code>$y= mx + b$</code> appears inline: $y = mx + b$</p>
<p>3) Enjoy math scripting with TeX!<br>Here are some <a href="http://www.mathjax.org/demos/tex-samples/" target="_blank" rel="external">TeX samples</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<p><a href="http://docs.mathjax.org/en/latest/mathjax.html" target="_blank" rel="external">MaxJax</a> is an open-source JavaScript display e]]>
    </summary>
    
      <category term="markdown" scheme="alyssaq.github.io/tags/markdown/"/>
    
      <category term="math" scheme="alyssaq.github.io/tags/math/"/>
    
      <category term="blog" scheme="alyssaq.github.io/categories/blog/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[View Math Equations in Markdown With Dropbox Image Hosting]]></title>
    <link href="alyssaq.github.io/2014/view-equation-in-markdown-with-dropbox-image-hosting/"/>
    <id>alyssaq.github.io/2014/view-equation-in-markdown-with-dropbox-image-hosting/</id>
    <published>2014-02-01T11:03:00.000Z</published>
    <updated>2015-10-18T08:43:47.000Z</updated>
    <content type="html"><![CDATA[<h2 id="Goal">Goal</h2><p>I wanted to show math equations in my github README.md</p>
<p>Update: I now use <a href="http://scriptogr.am/alyssa/post/view-math-equations-in-markdown-with-mathjax" target="_blank" rel="external">MathJax to view math equations in markdown</a>. I use dropbox to show images in this scriptogr.am blog.</p>
<h3 id="How_to_show_math_equations_in_the_browser">How to show math equations in the browser</h3><p>To do this, I was going to use <a href="http://www.w3.org/Math/mathml-faq.html" target="_blank" rel="external">MathML</a>, which<br>is an XML-based syntax for mathematical symbols to render in browsers.<br>Unfortunately,  markdown does <em>NOT</em> support MathML<br>☹</p>
<h3 id="How_to_show_math_equations_in_markdown">How to show math equations in markdown</h3><p>My work around was to convert the equations into images, host them somewhere and embed them in my README.md file.</p>
<p>You will need:</p>
<ol>
<li>An editor that is able to render MathML equations. (I use <a href="mouapp.com">mouapp</a>)   </li>
<li><a href="dropbox.com">Dropbox</a> or Google Drive to host your images for free. (I’ll be using dropbox)</li>
</ol>
<h3 id="Steps:">Steps:</h3><p>1) Copy the your MathML into your markdown editor (example below):<br>2) Take a screenshot of the rendered equation  <br><br>   (On Mac, to take an area-selected screenshot: command + shift + 4)<br>3) Place it in your dropbox folder and “Share Dropbox Link”:<br><img src="https://www.dropbox.com/s/z4ng9s65ot0kcws/share-dropbox-link.png?dl=1" alt="image"></p>
<p>4) Copy the link and add <strong>?dl=1</strong> at the end of the url to make it viewable when embedded in markdown:</p>
<pre><code><span class="symbol">https:</span>/<span class="regexp">/www.dropbox.com/s</span><span class="regexp">/{guid}/equation</span>1.png?dl=<span class="number">1</span>
</code></pre><p>5) Add it to your markdown!</p>
<pre><code>![<span class="link_label">image</span>](<span class="link_url">https://www.dropbox.com/s/{guid}/share-dropbox-link.png?dl=1</span>)
</code></pre><p>To center the image in markdown, you will have to use HTML:</p>
<pre><code><span class="tag">p</span> align=<span class="string">"center"</span>
  <span class="tag">img</span> src=<span class="string">"https://www.dropbox.com/s/{guid}/{}.png?dl=1"</span>
/p
</code></pre><p align="center"><br>  <img src="https://www.dropbox.com/s/opu9yg1a6j1zdve/equation1.png?dl=1"><br></p>

<p>6) Done! You have hosted your image with dropbox and embedded it<br>into your README.md for viewing on github</p>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="Goal">Goal</h2><p>I wanted to show math equations in my github README.md</p>
<p>Update: I now use <a href="http://scriptogr.am/alyss]]>
    </summary>
    
      <category term="dropbox" scheme="alyssaq.github.io/tags/dropbox/"/>
    
      <category term="markdown" scheme="alyssaq.github.io/tags/markdown/"/>
    
      <category term="math" scheme="alyssaq.github.io/tags/math/"/>
    
      <category term="blog" scheme="alyssaq.github.io/categories/blog/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Publish Your Node Module to NPM]]></title>
    <link href="alyssaq.github.io/2014/publish-your-node-module-to-npm/"/>
    <id>alyssaq.github.io/2014/publish-your-node-module-to-npm/</id>
    <published>2014-01-23T10:59:00.000Z</published>
    <updated>2015-10-18T08:43:35.000Z</updated>
    <content type="html"><![CDATA[<h2 id="Goal:">Goal:</h2><p>You have a node module and want in on npm registry for others to use by simply running: </p>
<pre><code>npm install <span class="tag">&lt;<span class="title">your_module_name</span>&gt;</span>
</code></pre><h2 id="Prerequisites">Prerequisites</h2><ol>
<li>Install <a href="http://nodejs.org" target="_blank" rel="external">nodejs</a></li>
<li>At least the following 3 files:<ul>
<li>package.json (run <code>npm init</code> to create one and follow the prompts)</li>
<li>README.md</li>
<li>&lt; module &gt;.js</li>
<li>&lt; module-test &gt;.js (optional but recommended. <a href="http://visionmedia.github.io/mocha/" target="_blank" rel="external">mocha</a> or <a href="http://pivotal.github.io/jasmine/" target="_blank" rel="external">jasmine</a> is good)</li>
</ul>
</li>
</ol>
<h2 id="Steps:">Steps:</h2><p>1) <strong>Register yourself on npm or login</strong><br>You can do this via the <a href="https://npmjs.org/signup" target="_blank" rel="external">npmjs</a> site or running</p>
<pre><code>npm <span class="built_ins">add</span>-<span class="built_ins">user</span>
</code></pre><p>and providing a username &amp; email.</p>
<p>2) <strong>Publish your node module to npm</strong>      </p>
<pre><code>npm publish <span class="tag">&lt;<span class="title">your_module_name</span>&gt;</span>
</code></pre><p><strong>Bam!</strong> You’re done.<br>Note: It will fail if the node module name is already taken.</p>
<h2 id="Other_housekeeping">Other housekeeping</h2><hr>
<h3 id="Update_your_published_node_module">Update your published node module</h3><p>Increment the version number in your <code>package.json</code>. Run</p>
<pre><code><span class="built_in">npm</span> publish 
</code></pre><p>Your node module is now updated!</p>
<h3 id="Uninstall_node_module">Uninstall node module</h3><pre><code>npm uninstall <span class="tag">&lt;<span class="title">module_name</span>&gt;</span>
</code></pre><h3 id="Example">Example</h3><p>My mini stats node module: <a href="http://github.com/alyssaq/stats-analysis" target="_blank" rel="external">github.com/alyssaq/stats-analysis</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="Goal:">Goal:</h2><p>You have a node module and want in on npm registry for others to use by simply running: </p>
<pre><code>npm inst]]>
    </summary>
    
      <category term="nodejs" scheme="alyssaq.github.io/tags/nodejs/"/>
    
      <category term="npm" scheme="alyssaq.github.io/tags/npm/"/>
    
      <category term="tech" scheme="alyssaq.github.io/categories/tech/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[2014 - Lets Blog]]></title>
    <link href="alyssaq.github.io/2014/2014--lets-blog/"/>
    <id>alyssaq.github.io/2014/2014--lets-blog/</id>
    <published>2014-01-22T19:48:00.000Z</published>
    <updated>2015-10-18T08:33:16.000Z</updated>
    <content type="html"><![CDATA[<h2 id="I_procrastinated,_now_I_shall_blog">I procrastinated, now I shall blog</h2><p>After storing years of life stories in my head, I’ve finally decided to blog.<br>In my defence, Ive tried many times. I have several online blogs, many to-do lists and scribbles of thoughts on paper, receipts, tissue papers and un-organised word documents.</p>
<p>This blog is not going to showcase my deep dark thoughts (maybe I’ll write them somewhere else) or daily life rambles. I want to keep the posts technical-related and document my learnings and summaries as a Software Engineer. </p>
<p>As of January 2014, I have left the corporate world and have joined the startup world. I go in as the first full-time employee in a team of 5. No surprises that this triggered the first post. In the last week, I’ve been working on a mini text-analytics engine in nodejs. </p>
<p>More learnings and how-to tutorials to be documented and hopefully help anyone else starting out.</p>
<p>This scriptogram (moved to hexo) blog rocks. Markdown ftw.</p>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="I_procrastinated,_now_I_shall_blog">I procrastinated, now I shall blog</h2><p>After storing years of life stories in my head, I’ve f]]>
    </summary>
    
      <category term="blog" scheme="alyssaq.github.io/tags/blog/"/>
    
      <category term="stuff" scheme="alyssaq.github.io/categories/stuff/"/>
    
  </entry>
  
</feed>
